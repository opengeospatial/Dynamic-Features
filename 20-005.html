<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<meta name="keywords" content="ogcdoc, OGC document, OGC, IndoorGML, Indoor space, Outdoor space, Seamless navigation, CityGML">
<title>Discussion paper for OGC Dynamic Features</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
</head>
<body class="discussion-paper editor">
<div id="header">
<h1>Discussion paper for OGC Dynamic Features</h1>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><strong class="big">i.     Abstract</strong></p>
</div>
<div class="paragraph">
<p>Moving Feature standards and technologies have made considerable progress. As they mature, implementations will move beyond our traditional Earth-centric framework. Extraterrestrial, deep space, and even virtual deployment environments must be considered.</p>
</div>
<div class="paragraph">
<p>It is time to re-evaluate the foundations of OGC standards to determine if they are sufficient to support these emerging deployment environments. This discussion paper examines ISO and OGC standards against current and anticipated future needs. It also examines other standards and conventions which may be useful for enhancing the OGC/ISO foundation.</p>
</div>
<div class="paragraph">
<p><strong class="big">ii.    Keywords</strong></p>
</div>
<div class="paragraph">
<p>The following are keywords to be used by search engines and document catalogues.</p>
</div>
<div class="paragraph">
<p>ogcdoc, OGC document,  &lt;tags separated by commas&gt;</p>
</div>
<div class="paragraph">
<p><strong class="big">iii.   Preface</strong></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
<div class="paragraph">
<p>Insert Preface Text here. Give OGC specific commentary: describe the technical content, reason for document, history of the document and precursors, and plans for future work. &gt;
Attention is drawn to the possibility that some of the elements of this document may be the subject of patent rights. The Open Geospatial Consortium shall not be held responsible for identifying any or all such patent rights.</p>
</div>
<div class="paragraph">
<p>Recipients of this document are requested to submit, with their comments, notification of any relevant patent claims or other intellectual property rights of which they may be aware that might be infringed by any implementation of the standard set forth in this document, and to provide supporting documentation.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><strong class="big">iv.    Submitting organizations</strong></p>
</div>
<div class="paragraph">
<p>The following organizations submitted this Document to the Open Geospatial Consortium (OGC):</p>
</div>
<div class="paragraph">
<p>Organization name(s)</p>
</div>
<div class="paragraph">
<p><strong class="big">v.     Submitters</strong></p>
</div>
<div class="paragraph">
<p>All questions regarding this submission should be directed to the editor or the submitters:</p>
</div>
<div class="paragraph">
<p>Name  Affiliation</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_scope">Scope</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Moving Feature standards and technologies have made considerable progress in recent years. As they mature, implementations will move beyond our traditional Earth-centric framework. Extraterrestrial, deep space, and even virtual deployment environments must be considered.</p>
</div>
<div class="paragraph">
<p>This paper focuses on Features which have a full three-dimensional geometry and are capable of movement, potentially at very high velocities. In addition, these Features may be independent of the Earth. WGS-84 and the Gregorian Calender have little relevance to a Feature flying through the Oort Cloud. Even less so for Features in artificial virtual worlds. Features with this expanded scope challenge the assumptions underlying both the OGC and ISO TC211 standards.</p>
</div>
<div class="paragraph">
<p>This paper provides an analysis of the existing OGC Standards baseline, seeking to assess how well it supports these new deployments and identifies any future work required.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_references">References</h2>
<div class="sectionbody">
<div class="paragraph">
<p>As a Discussion Paper, this document contains no normative references. Citations for resources referenced in this document are listed in the <a href="#bibliography_section">Bibliography</a> (Annex B).</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="terms_and_definitions_section">Terms and Definitions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>As a Discussion Paper, this document contains no normative definitions. The terms and definitions used in this discussion paper are documented in the <a href="#glossary_section">Glossary</a> (Annex C).</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_conventions">Conventions</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This sections provides details and examples for any conventions used in the document. Examples of conventions are symbols, abbreviations, use of XML schema, or special notes regarding how to read the document.</p>
</div>
<div class="sect2">
<h3 id="_identifiers">Identifiers</h3>
<div class="paragraph">
<p>The normative provisions in this document are denoted by the URI</p>
</div>
<div class="paragraph">
<p><a href="http://www.opengis.net/spec/{standard}/{m.n}" class="bare">http://www.opengis.net/spec/{standard}/{m.n}</a></p>
</div>
<div class="paragraph">
<p>All requirements and conformance tests that appear in this document are denoted by partial URIs which are relative to this base.</p>
</div>
</div>
<div class="sect2">
<h3 id="uml_notation_section">UML Notation</h3>
<div class="paragraph">
<p>The logical structure of the elements used in this Discussion Paper is presented using the Unified Modeling Language (UML) static structure diagram (see Booch et al. 1997). The UML notations used in this paper are described in the diagram in <a href="#figure-1">UML notation</a>.</p>
</div>
<div class="paragraph">
<p>Most of these UML diagrams have been extracted from the ISO/TC211 Harmonized Model maintained by the Harmonized Model Maintenance Group on their <a href="https://github.com/ISO-TC211/HMMG">GitHub Repository</a>. Some modifications may have been made to better present issues relevant to this discussion. None of these modifications change the underlying UML model.</p>
</div>
<div id="figure-1" class="imageblock text-center">
<div class="content">
<img src="images/UML_Notation.png" alt="UML Notation">
</div>
<div class="title">Figure 1. UML notation</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="dynamic_features_section">Space Objects</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Introductory text</p>
</div>
<div class="sect2">
<h3 id="feature_model_section">A Feature Model for Space Objects</h3>
<div class="paragraph">
<p>Before we can describe Space Objects, we must first have a conceptual model of the universe. The OGC and ISO TC211 provide that model in ISO 19109. This standard defines the General Feature Model (GFM). The GFM defines the concept of a Feature, its components, and behaviors.</p>
</div>
<div class="paragraph">
<p>ISO TC211 defines a Feature as an "Abstraction of real world phenomena" (ISO 19101-1:2014)</p>
</div>
<div class="paragraph">
<p>A Feature, then, is a high level abstraction for anything that does or could exist in the universe.</p>
</div>
<div class="paragraph">
<p>The General Feature Model further refines the concept of a Feature. The following principles are most relevant for this discussion:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>A Feature can be a FeatureType or an Instance of a FeatureType (AnyFeature).</p>
</li>
<li>
<p>FeatureTypes can form a taxonomy (inheritance)</p>
</li>
<li>
<p>Features possess characteristics (Properties)</p>
</li>
<li>
<p>A Property of a Feature can be an Operation, Attribute, or Association.</p>
</li>
</ol>
</div>
<div id="general_feature_model_figure" class="imageblock text-center">
<div class="content">
<img src="images/General-Feature-Model-L1.png" alt="General Feature Model L1">
</div>
<div class="title">Figure 2. General Feature Model</div>
</div>
<div class="paragraph">
<p>The resulting model is sufficient to describe a Feature&#8217;s identity (IdentifiedType), what it is (FeatureType), what it can do (Operations), its observable characterisitics (Attributes), and any associations with other Feature instances.</p>
</div>
<div class="paragraph">
<p><strong>Conclusion:</strong> ISO 19109 provides a model for Real World Objects that is suitable for non-terrestrial use.</p>
</div>
</div>
<div class="sect2">
<h3 id="geometry_in_3_d_section">Geometry in 3 Dimensions</h3>
<div class="paragraph">
<p>The applicable OGC/ISO standard for geometries is ISO 19107:2003. While a new version was approved in 2019, it hasn&#8217;t propagated through the rest of the ISO standards baseline. As a result, 19107:2003 is the most recent implemented version.</p>
</div>
<div class="sect3">
<h4 id="_features_and_geometry">Features and Geometry</h4>
<div class="paragraph">
<p>The General Feature Model treats geometry as an attribute of the Feature. In addition, it defines three types of attribute which are useful for associating geometry with a Feature in a standard manner:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>SpatialAttributeType: Geometries (GM_Object) and Topologies (TP_Object)</p>
</li>
<li>
<p>LocationalAttributeType: Named locations, extents, and points.</p>
</li>
<li>
<p>TemporalAttributeType: Temporal objects (TM_Object)</p>
</li>
</ul>
</div>
<div id="general_feature_model_attribute_types" class="imageblock text-center">
<div class="content">
<img src="images/AttributeTypes.png" alt="AttributeTypes">
</div>
<div class="title">Figure 3. General Feature Model Attribute Types</div>
</div>
<div id="general_feature_model_spatial_attribute_types" class="imageblock text-center">
<div class="content">
<img src="images/SpatialAttributeType.png" alt="SpatialAttributeType">
</div>
<div class="title">Figure 4. General Feature Model Spatial Attribute Types</div>
</div>
<div id="general_feature_model_locational_attribute_types" class="imageblock text-center">
<div class="content">
<img src="images/LocationalAttributeType.png" alt="LocationalAttributeType">
</div>
<div class="title">Figure 5. General Feature Model Locational Attribute Types</div>
</div>
<div id="general_feature_model_temporal_attribute_types" class="imageblock text-center">
<div class="content">
<img src="images/TemporalAttributeType.png" alt="TemporalAttributeType">
</div>
<div class="title">Figure 6. General Feature Model Temporal Attribute Types</div>
</div>
</div>
<div class="sect3">
<h4 id="_the_geometry_model">The Geometry Model</h4>
<div class="paragraph">
<p>An important feature of the ISO Geometry Model is that it does not specify or assume a coordinate reference system. The SC_CRS class, defined in ISO 19111, is used to define a coordinate reference system. The "Coordinate Reference System" association is used to associate a GM_Object instance with the appropriate SC_CRS instance. Since all geometry classes are decended from GM_Object, any geometry object can have its own unique coordinate reference system.</p>
</div>
<div id="gm_object_uml_model" class="imageblock text-center">
<div class="content">
<img src="images/GM_Object.png" alt="GM Object">
</div>
<div class="title">Figure 7. GM_Object UML Model</div>
</div>
<div class="paragraph">
<p>While the ISO Geometry Model is very complex, at its core is the DirectPosition class. This is the fundamental specification of a position within a coordinate reference system. Its purpose is simply to hold the coordinates for a position within the coordinate reference system.</p>
</div>
<div id="direct_position_uml_model" class="imageblock text-center">
<div class="content">
<img src="images/DirectPosition.png" alt="DirectPosition">
</div>
<div class="title">Figure 8. Direct Position UML Model</div>
</div>
<div class="paragraph">
<p>The DirectPosition class contains two attributes, "dimension" and "coordinate". The "coordinate" attribute is a sequence of numbers. Each number represents the location of the DirectPosition on a coordinate axis. There are no constraints on the number of numbers in the sequence. Therefore, a DirectPosition can represent an unlimited number of dimensions. The "dimension" attribute specifies the number of axis in the applicable coordinate reference system. This corresponds to the number of values in the "coordinate" sequence.</p>
</div>
<div class="paragraph">
<p>Like GM_Object, DirectPositions are associated with an SC_CRS through the cordinateReferenceSystem association. This association is typically not used since DirectPositions, as data types, will usually be included in larger objects (such as GM_Objects) that have their own references to SC_CRS. When this association is left NULL, the coordinate reference system of the DirectPosition instance will take on the value of the containing object&#8217;s SC_CRS.</p>
</div>
<div class="paragraph">
<p>One limitation of the DirectPosition class is that it does not support complex numbers. However, since DirectPosition does have a "coordinateReferencesystem" association with SC_CRS, it should be possible to model complex numbers in the CRS definition as as two orthagonal axis.</p>
</div>
<div class="paragraph">
<p><strong>Conclusion:</strong> The ISO 19107 Geometry Model is suitable for geometries of three or more dimensions.</p>
</div>
<div class="paragraph">
<p><strong>Issue:</strong> Support for coordinate values which are complex numbers needs to be validated.</p>
</div>
</div>
<div class="sect3">
<h4 id="_features_in_3d">Features in 3D</h4>
<div class="paragraph">
<p>In our discussion of Dynamic Features, we must allow for Features which are moving through three dimensions and have non-trivial three dimensional shapes. We must also consider that the shape of these objects may change with time. From this we see that the movement of the Feature and the shape of the Feature are two separate properties.</p>
</div>
<div class="paragraph">
<p>A measurement of movement would capture changes in location and orientation. Movement is measured from the perspective of an external observer. Therefore, movement should be specified using a coordinate reference system which is external to the Feature.</p>
</div>
<div class="paragraph">
<p>The shape of a Feature is independent of its location. A rigid body has the same shape regardless of where it is or who is observing it. It&#8217;s geometry should be self-contained. This requires use of an internal coordinate reference system.</p>
</div>
<div class="paragraph">
<p>This leads up to two postulates:</p>
</div>
<div class="paragraph">
<p><strong>Postulate 1:</strong> The Locational Attribute of a 3D Feature is a GM_Point which locates the origin of the local CRS within an <a href="#external_coordinate_reference_system_definition">external CRS</a>.</p>
</div>
<div class="paragraph">
<p><strong>Postulate 2:</strong> The Spatial Attribute of a 3D Feature is one or more GM_Objects which define the shape of the Feature in the <a href="#local_coordinate_reference_system_definition">local coordinate refrence system</a>.</p>
</div>
<div class="sect4">
<h5 id="_3d_geometries">3D Geometries</h5>
<div class="paragraph">
<p>ISO 19107 makes a distinction between a geometric object and the surface which contains that object. One advantage of this approach is that there can be multiple surfaces associated with one object. For example, an island located in a lake would be represented by an interior surface (the island) of a polygon (the lake) bounded by the exterior surface (the shoreline).</p>
</div>
<div class="paragraph">
<p>ISO 19107 uses the GM_Object class to define an object and the GM_Boundary class to define a containing surface. Both GM_Object and GM_Boundary are defined as root level geometry classes. The association between GM_Object and GM_Boundary is achieved through the “boundary()” operation on the GM_Object class. This operation is inherited by all subclasses of GM_Object.</p>
</div>
<div class="paragraph">
<p>In the case of a 3D Feature, GM_Solid is the subclass of GM_Object while GM_SolidBoundary is the subclass of GM_Boundary. GM_Solid describes the volume while GM_SolidBoundary describes the shape.</p>
</div>
<div id="geometry_in_3d_uml_model" class="imageblock text-center">
<div class="content">
<img src="images/Geometry_3D.png" alt="Geometry 3D">
</div>
<div class="title">Figure 9. 3D Geometry UML Model</div>
</div>
</div>
<div class="sect4">
<h5 id="_volumes">Volumes</h5>
<div class="paragraph">
<p>GM_Object is subclassed into GM_Primitive and then into GM_Solid.  The “volume()” operation on GM_Solid returns the volume (defined in ISO 19103) of space contained within that GM_Solid. Thus, ISO 19107 supports the concept of a 3D volume.</p>
</div>
<div class="paragraph">
<p>Real 3D objects are often not solid. So the 3D model must also support voids, or even entire 3D Features within their interior. GM_Primitive addresses this need through the “interior to” association. The two roles on this association are the containingPrimitive (the GM_Primitive which contains another GM_Primitive) and the containedPrimitive (the GM_Primitive which is contained). This association has proven its worth in 2D space so there is little doubt that it will be just as effective in 3D.</p>
</div>
</div>
<div class="sect4">
<h5 id="_shapes">Shapes</h5>
<div class="paragraph">
<p>A 3D volume is delineated by a bounding surface.  GM_Boundary is the root class for boundaries. The subclass GM_PrimitiveBoundary provides the boundary for GM_Primitives. The GM_PrimitiveBoundary subclass GM_SolidBoundary is defined as the boundary for a GM_Solid.</p>
</div>
<div id="boundaries_in_3d_uml_model" class="imageblock text-center">
<div class="content">
<img src="images/Boundary_3D.png" alt="Boundary 3D">
</div>
<div class="title">Figure 10. 3D Boundaries UML Model</div>
</div>
<div class="paragraph">
<p>ISO 19107 goes even farther. A GM_SolidBoundary is composed of both interior and exterior boundaries. These boundaries are defined by the GM_Shell class. Following the class associations we see:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A GM_Shell is a GM_CompositeSurface</p>
</li>
<li>
<p>A GM_CompositeSurface is composed of
GM_OrientablePrimitives</p>
</li>
<li>
<p>A GM_Surface is a type of GM_OrientablePrimitive</p>
</li>
<li>
<p>A GM_PolyhedralSurface is a type of GM_Surface</p>
</li>
<li>
<p>A GM_PolyhedralSurface can be composed of
GM_Polygons</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>A GM_PolyhedralSurface which is composed of GM_Polygons is an example of Boundary Representation (B-Rep) of a surface. This approach is fundamental to rendering 3D computer graphics. (ref Adam Powers 1981)</p>
</div>
<div class="sect5">
<h6 id="_closure_surfaces">Closure Surfaces</h6>
<div class="paragraph">
<p>Some structures, such as a tunnel or overpass, pose difficulties for this geometry model. The boundary surface can be constructed so that it continues into the interior of the structure. That would make the interior of a tunnel external to the tunnel object. This is not always a desireable result. CityGML provides the concept of a "Closure Surface".</p>
</div>
<div class="paragraph">
<p>A Closure Surface is a surface which is a logical part of the object but does not correspond to a physical part of the object. For example, the entrance to a tunnel can have a closure surface. This surface allows you to treat the tunnel as a three-dimension solid, even though there is a hole in the bounding surface.</p>
</div>
<div id="closure_surface_uml_model" class="imageblock text-center">
<div class="content">
<img src="images/Closure_Surface.png" alt="Closure Surface">
</div>
<div class="title">Figure 11. Closure Surface UML Model</div>
</div>
<div class="paragraph">
<p>As implemented in CityGML 3.0, the ClosureSurface class has quite an ancestory. We may want to generalize this concept for use outside of CityGML. However, the capabilties provided by the ancestor classes do provide value and may be worth incorporating into a general 3D model.</p>
</div>
</div>
<div class="sect5">
<h6 id="_b_rep">B-Rep</h6>
<div class="paragraph">
<p>The polyhedral surfaces which bound volumetric shapes are similar to the Boundary Representation (B-Rep) approach used in CAD and computer graphics. B-Rep defines a 3-dimensional surface which serves as the interface between the interior of the volumetric shape and the exterior. This surface is usually defined by a collection of shape elements (polygons) which together form a closed surface.</p>
</div>
<div class="paragraph">
<p><a href="https://en.wikipedia.org/wiki/Boundary_representation" class="bare">https://en.wikipedia.org/wiki/Boundary_representation</a></p>
</div>
</div>
<div class="sect5">
<h6 id="_point_clouds">Point Clouds</h6>
<div class="paragraph">
<p>Boundary surfaces can also be defined using 3D point clouds. This allows the spatial represention a bounding surface by a set of points located on that surface. In this way, the geometry of a Feature could, for instance, be modelled directly from the result of a mobile laser scanning campaign.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_conclusions_and_future_work">Conclusions and Future Work</h4>
<div class="paragraph">
<p>The ISO 19107 Geometry Model appears to be suitable for representing complex, non-terrestrial objects of three or more dimensions. But will it work in reality?</p>
</div>
<div class="paragraph">
<p>An example of this Geometry Model applied to a practical application can be found in the CityGML family of standards. CityGML uses the 19107 geometry model to define buildings, the exterior spaces surounding the buildings, as well as interior spaces and even movable furniture. This should be sufficient for any complex object, whether on the surface of the Earth or in Space.</p>
</div>
<div class="paragraph">
<p><strong>Conclusion:</strong> The ISO 19107 Geometry Model is sufficient to represent the geometry of complex space objects.</p>
</div>
<div class="paragraph">
<p>Two techniques have been described to represent the surface of a 3D object, point clouds and B-Rep. This list is certainly not exhausitve. According to ISO 19107, a GM_SolidBoundary object is composed of GM_Shell objects. But the Standard does not provide a decomposition of GM_Shell. So there is no way to specify the geometry underlying the shell.</p>
</div>
<div class="paragraph">
<p><strong>Issue:</strong> Can and should we extend the GM_Shell class of ISO 19107 to address the underlying geometry of the surface of a 3D object?</p>
</div>
<div class="paragraph">
<p>The GM_Solid and GM_SolidBoundary classes are designed to represent a 3D space. It is not clear if they can also represent a 4D or even 5D space. While it&#8217;s clear that the basic coordinate representation is independent of the number of dimensions, that may not be true of the more complex geometry constructs.</p>
</div>
<div class="paragraph">
<p><strong>Issue:</strong> Can the GM_Solid and GM_SolidBoundary classes represent an n-dimensional solid?</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="moving_features_section">Moving Features</h3>
<div class="paragraph">
<p>The ISO Standard for Moving Features is ISO 19141:2008. This standard extends the geometry model from ISO 19107 and, by association, the Feature Model from ISO 19109.</p>
</div>
<div id="moving_features_figure" class="imageblock text-center">
<div class="content">
<img src="images/Movement.png" alt="Movement">
</div>
<div class="title">Figure 12. Moving Features</div>
</div>
<div class="paragraph">
<p>A high level view of ISO 19141 is provided in <a href="#moving_features_figure">Figure 11</a>. The classes identified in this figure are described below. But first, a discussion of coordinate reference systems (CRS) is in-order.</p>
</div>
<div class="sect3">
<h4 id="_coordinate_systems">Coordinate systems</h4>
<div id="external_global_local_crs" class="imageblock text-center">
<div class="content">
<img src="images/LocalGlobalCRS.png" alt="LocalGlobalCRS">
</div>
<div class="title">Figure 13. External, Global, and Local CRS</div>
</div>
<div class="paragraph">
<p>Moving Features deal with three spatial coordinate systems as well at one temporal coordinate system. The spatial coordinate systems are referred to as the External, Global, and Local CRS (see <a href="#external_global_local_crs">Figure 12</a>).</p>
</div>
<div class="paragraph">
<p>When dealing with Moving Features, we frequently need to convert coordinates between the three spatial CRS. The GM_Object class provides us with the transform() operation which can be used for this purpose.</p>
</div>
<div class="sect4">
<h5 id="_external_crs">External CRS</h5>
<div class="paragraph">
<p>The <a href="#external_coordinate_reference_system_definition">External coordinate system</a> is the coordinate system within which the Moving Feature exists. Typically this is an Earth-centric geographic CRS such as WGS 84.</p>
</div>
</div>
<div class="sect4">
<h5 id="_local_crs">Local CRS</h5>
<div class="paragraph">
<p>The <a href="#local_coordinate_reference_system_definition">local coordinate system</a> is internal to the Feature. This is usually a cartisian coordinate system with the origin at a prominent point in the Feature such as the center of mass.
For rigid bodies, the local coordinate system is fixed over time. It does not change reqardless of any motion by the associated Feature.</p>
</div>
<div class="paragraph">
<p>This constraint does not hold for non-rigid bodies. This case will be discussed in the sections on <a href="#articulated_geometries_section">articulated geometries</a> and <a href="#plastic_geometries_section">plastic geometries</a>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_global_crs">Global CRS</h5>
<div class="paragraph">
<p>The <a href="#global_coordinate_reference_system_definition">Global coordinate system</a> provides a transition between the External CRS and Local CRS. It is a moving CRS which follows the trajectory of the Moving Feature. As such, it provides the External CRS a time variant local reference system, while providing a time invariant context for the Local CRS.</p>
</div>
<div class="paragraph">
<p>The origin of the Global CRS is the location of the Moving Feature on the trajectory curve at a specific time. From the perspective of the External CRS, the origin translates as a funcion of time. From the perspective of the Internal CRS, however, the origin of the Global CRS is static.</p>
</div>
<div class="paragraph">
<p>The axis of the Global CRS can be defined using two techniques.</p>
</div>
<div class="paragraph">
<p>The first approach treats the Moving Feature as a black box viewed by an external observer. From this perspective, the Global CRS is defined in terms of the trajectory alone. No knowledge of the properties or even the shape of the Moving Feature are required. This CRS starts by defining x and y as two orthagonal axis which define a plane tangential to the Trajectory curve at the origin. Positive x is in the direction of motion. The positive y axis is perpendicular to the x axis and forms either a right or left handed CRS. The z axis is perpendicular to the tangent plane. Positive z can be either up or down. The result is a cartesian refernce system which is always tangential to the trajectory of the Moving Feature.</p>
</div>
<div class="paragraph">
<p>The second approach defines the Global CRS in terms of motion properties of the Moving Feature. The x axis, for example, could be defined as the heading of the Moving Feature. This is the direction the Feature is pointing, but not necessarily the direction it is moving. The y and z axis can be defined using similar properties (for example; pitch, yaw, and roll).</p>
</div>
<div class="paragraph">
<p>In general, the black box approach is appropriate for ballistic Moving Features. Cases where the Feature is not anticipated to take any actions which would modify the trajectory. The motion properties approach is appropriate for navigated Moving Features. Cases where a Feature is expected to take actions which would modify the trajectory.</p>
</div>
</div>
<div class="sect4">
<h5 id="_temporal_reference_systems">Temporal Reference Systems</h5>
<div class="paragraph">
<p>ISO 19108:2006 Geographic Schema - Temporal Schema is the ISO standard for Temporal Reference Systems. In particular, the TM_ReferenceSystem class.</p>
</div>
<div class="paragraph">
<p>TM_ReferenceSystem has two attributes; <code>domainOfValidity</code> and <code>name</code>. The <code>name</code> attribute is an identifier for this temporal reference system. The <code>domainOfValidity</code> specifies the spatial extent over which this TRS is applicable.</p>
</div>
<div class="paragraph">
<p>TM_ReferenceSystem is specialized through a number of subclasses. The two most relevant to this paper are TM_CoordinateSystem and TM_Clock.</p>
</div>
<div class="paragraph">
<p>TM_CoordinateSystem is "A system for measuring time on a continuous interval scale using a single standard time interval". The standard time interval is provided through the <code>interval</code> attribute. In addition, the <code>origin</code> attribute provides a temporal "datum" from which time is measured. Since time is a one-dimensional quantity, the origin and interval are sufficient to define a basic Temporal Coordinate Reference System.</p>
</div>
<div class="paragraph">
<p>TM_Clock is "A system for measuring temporal position within a day". It has an optional <code>dateBasis</code> association with a calendar (TM_Calendar).</p>
</div>
<div class="paragraph">
<p>This combination of classes allows us support high precision local-clock TRS as well as full date-time TRS.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_coordinate_representation">Coordinate Representation</h4>
<div class="paragraph">
<p>The coordinates used to define a 3D moving geometry (MG) face requirements specific to their use. These requirements are derived from two characteristics of moving geometries. Unlike static spatial geometries, time and location in moving geometries are tightly coupled. They must act as a single, four dimension location. In addition, there will be a large number of coordinate measurements. This is a result of the need to accurately track movement over time.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>A MF coordinate must represent a discrete location in space and time.</p>
</li>
<li>
<p>A MF coordinate must include values for all three spatial axis (X,Y,Z) as well as the temporal axis (t).</p>
</li>
<li>
<p>A MF coordinate must be concise.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Of the Moving Feature encoding standards, the JSON encoding comes closest to meeting these requirements. Its major shortfall is the need for conformance with GeoJSON. Since GeoJSON assumes a terrestrial spatial geometry, spatial and temporal coordinates must be encoded separately.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A LinearTrajectory object SHALL be a GeoJSON Feature object that has two MANDATORY members of "geometry" and "properties".</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The spatial locations are captured using the GeoJSON "geometry" property. This property is restricted as follows:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The value of the "geometry" member SHALL be a LineString Geometry object, having "type" = "LineString".</p>
</li>
<li>
<p>The number of elements in the array of the "coordinates" value in the Geometry object SHALL be more than two positions.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>So the spatial geometry is a linestring of more than two points.</p>
</div>
<div class="paragraph">
<p>GeoJSON does not support temporal coordinates directly. So the "properties" property is adapted for this purpose. Since "properties" is not limited to temporal coordinates, these requirements are more complex.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The value of the "properties" member SHALL be a GeoJSON object that has at least one member with the name "datetimes".</p>
</li>
<li>
<p>The value of the "datetimes" member is a JSON array.</p>
</li>
<li>
<p>Each element in the "datetimes" array SHALL be an instant object.</p>
</li>
<li>
<p>An instant object SHALL be a JSON string that represents a timestamp encoded in the IETF RFC 3339 format using <code>Z</code> or
the numeric value of milliseconds since midnight (00:00 a.m.) on January 1, 1970, in UTC.</p>
</li>
<li>
<p>The members of the <code>"datetimes"</code> array SHALL be a monotonic increasing sequence.</p>
</li>
<li>
<p>There SHALL be no instant object that has the same value as any other element.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The consequence of these requirements is that the "properties" property can carry the temporal equivalent to a line string. There is one final requirement.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The number of elements in both arrays of the "coordinates" value and the "datetimes" value SHALL be equal.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>So there is a one-to-one correspondance between the temporal measurements in the "properties" property and the spatial measurements in the "geometry" property.</p>
</div>
<div class="paragraph">
<p>An example of this encoding is provided ---</p>
</div>
<div class="literalblock">
<div class="content">
<pre>{
    "type": "Feature",
    "id": "A",
    "geometry": {
        "type": "LineString",
        "coordinates": [[11.0,2.0,50.0], [12.0,3.0,52.0], [10.0,3.0,56.0]]
    },
    "properties": {
        "datetimes": ["2012-01-17T12:33:51Z", "2012-01-17T12:33:56Z", "2012-01-17T12:34:00Z"],
        "state": ["walking", "walking"],
        "typecode": [1, 2]
    }
},</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_geometry">Geometry</h4>
<div class="sect4">
<h5 id="_mf_oneparametergeometry">MF_OneParameterGeometry</h5>
<div class="paragraph">
<p>We start our discussion of Moving Feature geometries with the class MF_OneParameterGeometry. MF_OneParameterGeometry is a subclass of GM_Object. So moving features have the 3D geometric properties of any other GM_Object. What is different is that this geometry can change as a function of a parameter.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<div class="title">Note</div>
</td>
<td class="content">
verify the following definition and clarify the symbology. It does not appear to render correctly.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>A one parameter set of geometries is defined as "a function f from an interval t Î [a, b] such that f(t) is a geometry and for each point P Î f(a) there is a one parameter set of points (called the trajectory of P) P(t) : [a, b] ® P(t) such that P(t) Î f(t). A leaf of a one parameter set of geometries is the geometry f(t) at a particular value of the parameter".</p>
</div>
<div class="paragraph">
<p>A one parameter geometry instance includes a "leafgeometry()" operation. This operation takes the parameter (t) as input and returns the leaf P(t) for that parameter as a GM_Object.</p>
</div>
</div>
<div class="sect4">
<h5 id="_mf_temporalgeometry">MF_TemporalGeometry</h5>
<div class="paragraph">
<p>An MF_TemporalGeometry is a MF_OneParameterGeometry where the parameter is Time expressed as a TM_Coordinate. TM_Coordinate is specified in ISO 19108. It expresses time as a multiple of a single unit of measure such as year, day, or second. The "leafgeometry()" operation of an instance of MF_TemporalGeometry would take a TM_Coordinate in as input and return a GM_Object instance representing the geometry of the Feature at the specified point in time.</p>
</div>
</div>
<div class="sect4">
<h5 id="_temporal_properties">Temporal Properties</h5>
<div class="paragraph">
<p>The JSON encoding of the OGC Moving Features standard introduces the concept of temporal properties.</p>
</div>
<div class="paragraph">
<p>"A TemporalProperties object is a JSON array of ParametricValues objects that groups a collection of dynamic non-spatial attributes and its parametric values with time."</p>
</div>
<div class="paragraph">
<p>Logically TemporalProperties should be a subclass of MF_OneParamProperties. Since Geometry is a property, then MF_TemporalGeometry should be a subclass of TemporalProperties. Which gives us the following UML.</p>
</div>
<div id="temporal_properties_figure" class="imageblock text-center">
<div class="content">
<img src="images/Temporal_Properties.png" alt="Temporal Properties">
</div>
<div class="title">Figure 14. Temporal Properties</div>
</div>
<div class="paragraph">
<p>Temporal properties are particularly useful for capturing state change. For example, the fuel load of an aircraft will change over time. The leafproperty() operation on a temporal fuel_load object would return the amount of fuel onboard at the specified time.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_location">Location</h4>
<div class="paragraph">
<p>ISO 19141 represents the location of a Moving Feature using two classes; MF_Trajectory and MF_TemporalTrajectory.</p>
</div>
<div id="trajectory_figure" class="imageblock text-center">
<div class="content">
<img src="images/MF_Trajectory.png" alt="MF Trajectory">
</div>
<div class="title">Figure 15. Trajectory</div>
</div>
<div class="paragraph">
<p>A MF_Trajectory is a curve (GM_Curve). It represents every postion that the Feature has occupied during it&#8217;s journey. It does not necessarily represent the time when each location was reached.</p>
</div>
<div class="paragraph">
<p>MF_TemporalTrajectory makes the MF_Trajectory a MF_TemporalGeometry. It represents location along the trajectory as a function of time. So each location is fully defined in both space and time.</p>
</div>
<div class="paragraph">
<p>A Temporal Trajectory has two operations of particular interest; leaf() and leafgeometry(). The input parameter for these operations is always time (TM_Coordinate).</p>
</div>
<div class="paragraph">
<p>The leaf() operation returns the spatial location (Direct_Position) that the Moving Feature passes at the time (TM_Coordinate) specified by the input parameter. This is a point on the trajectory GM_Curve geometry. It also serves as the origin of the Global CRS at that location on the trajectory.</p>
</div>
<div class="paragraph">
<p>The LeafGeometry() operation returns the spatial geometry (GM_Point) that this Moving Feature possesses at the time (TM_Coordinate) specified by the input parameter. This is the shape of the Moving Feature expressed in the Local CRS. Since Trajectories only convey location, only GM_Point geometries are supported.</p>
</div>
</div>
<div class="sect3">
<h4 id="_orientation">Orientation</h4>
<div class="sect4">
<h5 id="_mf_prismgeometry">MF_PrismGeometry</h5>
<div class="paragraph">
<p>If an application focuses on only the linear movement (i.e., the spatiotemporal line string) of moving points based on World Geodetic System 1984, with longitude and latitude units of decimal degrees, and the ISO 8601 standard for representation of dates and times using the Gregorian calendar, the application can share the trajectory data by using <strong>only</strong> IETF GeoJSON, called <strong>MF-JSON Trajectory</strong>. For other cases, <strong>MF-JSON Prism</strong> can be used for expressing more complex movements of moving features. <strong>MF-JSON Prism</strong> is a GeoJSON-like format reserving new members of JSON objects (`"temporalGeometry," "temporalProperties," "crs," "trs," "time," and others) as "foreign members" to represent spatiotemporal geometries, variations of measure, coordinate reference systems, and the particular period of moving features in a JSON document.</p>
</div>
<div class="paragraph">
<p>A trajectory provides the location of a Moving Feature as a function of time. Prism Geometry represents the full geometry (location, orientaion, and shape) of the Feature as a function of time.</p>
</div>
<div id="foliation_figure" class="imageblock text-center">
<div class="content">
<img src="images/Foliation.png" alt="Foliation">
</div>
<div class="title">Figure 16. Foliation</div>
</div>
<div class="paragraph">
<p>The key concepts in the Prism model are:</p>
</div>
<div class="paragraph">
<p><strong>Leaf:</strong> A leaf is the geometry of the Moving Feature at time (tn).</p>
</div>
<div class="paragraph">
<p><strong>Foliation:</strong> A collection of leaves where there is a complete and separate representation of the geometry of the Feature for each specific time (tn).</p>
</div>
<div class="paragraph">
<p><strong>Trajectory:</strong> A curve that represents the path of a point in the geometry of the Moving Feature as it moves with respect to time (t).</p>
</div>
<div class="paragraph">
<p><strong>Prism:</strong> the union of the geometries (or the union of the trajectories) in a foliation.</p>
</div>
<div class="paragraph">
<p>Like a Temporal Trajectory, a Prism is a subclass of MF_TemporalGeometry.</p>
</div>
<div id="prism_context_figure" class="imageblock text-center">
<div class="content">
<img src="images/Prism_Context.png" alt="Prism Context">
</div>
<div class="title">Figure 17. Prism Context</div>
</div>
<div class="paragraph">
<p>A MF_PrismGeometry class has the following characteristics.</p>
</div>
<div class="paragraph">
<p>The association role "originTrajectory" associates a Temporal Trajectory with a Prism geometry. For any TM_Position:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>the associated Temporal Trajectory provides the location of the Moving Feature in the Global CRS.</p>
</li>
<li>
<p>this location serves as the origin of the Local CRS.</p>
</li>
<li>
<p>the prism geometry is defined in that Local CRS.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>The localCoordinateSystem() operation returns a SC_CRS for the <a href="#design_coordinate_reference_system_definition">design coordinate reference system</a> in which the moving feature&#8217;s shape is defined. This is usually the same as the <a href="#local_coordinate_reference_system_definition">local coordinate system</a>.</p>
</div>
<div class="paragraph">
<p>The rotationAtTime() operation accepts a time in the domain of the prism geometry and returns the rotation matrix that embeds the local geometry into geographic space at a given time (TM_Coordinate). The vectors of the rotation matrix allow the feature to be aligned and scaled as appropriate to the vectors of the global coordinate reference system.</p>
</div>
<div class="paragraph">
<p>This one association and two operations provide us with the location, orientation, axis definition, and units of measure needed to define identify the local CRS and to transform geometries between the Local and Global CRS.</p>
</div>
<div class="paragraph">
<p>Finally, the geometryAtTime() operation accepts a time in the domain of the prism geometry and returns the geometry of the moving feature, as it is at a given time in the global coordinate reference system. The return type is a GM_Object so this operation is not limited to points. It is fully capable of representing a 3D surface and volume.</p>
</div>
<div class="paragraph">
<p>In short, a MF_PrismGeometry provides us with the shape, location, and orientation of a Moving Feature as a funtion of time (tn).</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_non_rigid_bodies">Non-rigid Bodies</h4>
<div class="paragraph">
<p>ISO 19141 only addresses rigid bodies. The shape returned by a geometryAtTime() operation will always be the same. However, it leaves open the opportunity to extend the Moving Feature model to support plastic (non-rigid) objects.</p>
</div>
<div class="paragraph">
<p>The most obvious approach is to allow the geometry returned by the geometryAtTime() operation to change as a function of time. This doesn&#8217;t require a change to the model. But it may require some changes to the standard.</p>
</div>
<div class="paragraph">
<p>As a correlary to this approach, the geometry itself could include MF_TemporalGeometry elements. These elements would each have their own lifespan. A history of their movement, in respect to the local CRS, over time.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="articulated_geometries_section">Articulated Geometries</h3>
<div class="paragraph">
<p>Given a suite of standards which allow you to define time-variant geometric elements, then the next step is to take a collection of those elements and assemble them into a complex object.</p>
</div>
<div class="paragraph">
<p>An articulated geometry is such an aggregation where each element has one (1) to six (6) degrees of freedom. Each element can move, but its movement is constrained by attachment to one or more additional elements.</p>
</div>
<div class="paragraph">
<p>The aggregate as a whole can also move, but that movement becomes more complex. Typically we would model movement of the whole as a trajectory of the center of mass. However, the center of mass of an articulating Feature may change as the relative position of the elements change.</p>
</div>
<div class="paragraph">
<p>Two existing standards address the problem of Articulated Geometries. The MISB Staging System was developed for articulated Motion Imagery capture systems. GeoPOSE also addresses Motion Imagery, but it is more focused on Augmented and Virtual reality.</p>
</div>
<div class="paragraph">
<p>It is not likely that either standard provides a complete solution. Their relative merits and deficiencies are discussed in the <code>Discussion</code> section as well as proposals for work to be done.</p>
</div>
<div class="sect3">
<h4 id="_misb_staging_system">MISB Staging System</h4>
<div class="paragraph">
<p>The Motion Imagery Standards Board (MISB) develops standards for motion imagery, audio, associated metadata, and their related systems. Exploitation of MISB data requires its precise positioning in space and time. Therefore, a number of MISB standards deal with the derivation of ground coordinates from sensor coordinates.</p>
</div>
<div class="paragraph">
<p>Motion Imagery systems are typically complex structures consisting of multiple components each capable of independent motion. Measurements of these motions are in a local coordinate reference system. Conversion of a sensor coordinate requires a series of transformations, starting from the detector and working back through the attached components to a core, geolocated component.</p>
</div>
<div class="paragraph">
<p>Further complicating maters, each component is capable of movement. The transformations are not fixed. They must be calculated from the relative position of each component at the time that the detection was made. This leads to a requirement that for every observation, the relative position and orientation of each component of the collecting system must be captured as well.</p>
</div>
<div class="paragraph">
<p>The MISB 1906 Motion Imagery Metadata (MIMD): Staging System standard addresses this requirement. This standard captures the locations, orientations, and kinemantics (velocity, acceleration, etc.) of platforms, gimbals, sensors, sensor elements, geospatial and other points. The locations and orientations are either absolute references to a well-known frame of reference (e.g., WGS84) or relative references to other locations and orientations. Each location and orientation pairing define a “stage” that has the potential to be the frame of reference for another location and orientation. Linking stages together forms the Staging System. The Staging System then defines an ability to describe, in metadata, the physical make-up and configuration of a system and the time varying physical relationships of the system and its sub-system components.</p>
</div>
<div class="paragraph">
<p>A UML model for the MISB Staging System is provided in <a href="#figure-staging-system-uml">Figure 17</a>.</p>
</div>
<div id="figure-staging-system-uml" class="imageblock text-center">
<div class="content">
<img src="images/Staging_UML.png" alt="Staging UML">
</div>
<div class="title">Figure 18. MISB Staging System UML Model</div>
</div>
<div class="paragraph">
<p>This model only addresses a single stage. Non-trivial systems will require multiple stages. These stanges are assembled using the <code>parentStage</code> association of the <code>Stage</code> class. The following three concepts guide the construction of multiple-stage models:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Stage:</strong> a single frame of reference located at a point. It defines the location, orientation, and kinemantics of a coordinate system located at that point. These properties can be defined in terms of absolute values, or as relative values measured from an "parent" reference system.</p>
</li>
<li>
<p><strong>Constellation:</strong> A system of one or more stages where the parent-child relationships between the stages is sufficient to calculate the absolute values for every stage.</p>
</li>
<li>
<p><strong>Root Stage:</strong> This is the starting point for a Constellation. This stage is expressed in absolute values (AbsGeocentric or AbsGeodetic).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>An example articulated motion imagery system is illustrated in <a href="#figure-staging-system-example">Figure 18</a>. The stages which describe this system are described in <a href="#lp-resources-table">Table 1</a>.</p>
</div>
<div id="figure-staging-system-example" class="imageblock text-center">
<div class="content">
<img src="images/Staging_Example.png" alt="Staging Example">
</div>
<div class="title">Figure 19. MISB Staging System Example</div>
</div>
<div class="paragraph">
<p>Example Motion Imagery System with Multiple Sensors and Gimbals
(Photo credit White Sands Missile Range)</p>
</div>
<table id="lp-resources-table" class="tableblock frame-all grid-all" style="width: 90%;">
<caption class="title">Table 1. Stage System Example</caption>
<colgroup>
<col style="width: 10%;">
<col style="width: 40%;">
<col style="width: 10%;">
<col style="width: 40%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Stage</th>
<th class="tableblock halign-left valign-top">Component</th>
<th class="tableblock halign-left valign-top">Parent</th>
<th class="tableblock halign-left valign-top">Values</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Reference Frame Survey Point</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Absolute Position/Orientation</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Trailer</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Relative Position / Orientation</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left Camera</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Relative Position / Orientation</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right Camera</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Relative Position / Orientation</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Top Center Gimbal</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Relative Position / Orientation</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Left Upper Camera</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Relative Position / Orientation</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Right Upper Camera</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Relative Position / Orientation</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The Staging System’s absolute positions use either WGS84 Ellipsoid angular coordinates (i.e., geodetic Latitude, Longitude, Height above Ellipsoid (HAE)), or WGS84 geocentric Earth-Centered Earth-Fixed (ECEF) Cartesian coordinates (i.e., X, Y, Z).</p>
</div>
<div class="paragraph">
<p>The Staging System’s relative positions use Cartesian coordinates (i.e., x, y, z) measured in meters from the parent stage frame of reference.</p>
</div>
<div class="paragraph">
<p>The Staging System’s orientations use Euler rotations, measured in radians, around three axes (X, Y, and Z) of a righthanded coordinate system. The Staging System’s absolute orientation has the X, Y, and Z axes aligned with the East, North, and Up (ENU) axis respectively.</p>
</div>
<div class="paragraph">
<p>The Staging System standardizes rotations to use a specific order of rotations. The Staging System uses Tait-Bryan angles with a Primary Rotation Order of Z-Y-X. The first rotation is around the Z-axis, the second rotation is around the new Y-axis (after rotation around the Z-axis), the final rotation is around the new X-axis (after rotation around the Z and then Y axes).</p>
</div>
<div class="paragraph">
<p>The Staging system does not explicity address temporality. However, this information is passed in the MISB KLV metadata stream. As such, each update is associated with the precision time stamp of that packet.  In addition, an update can be associated with a Timer as described in section ----</p>
</div>
</div>
<div class="sect3">
<h4 id="_geopose">GeoPOSE</h4>
<div class="paragraph">
<p>GeoPOSE is a proposed OGC standard which provides a general purpose alternative to the MISB Staging System. This standard deals with the location and orientation of real or virtual geometric objects (Poses) and the aggregation of Poses into more complex structures.</p>
</div>
<div class="sect4">
<h5 id="_core">Core</h5>
<div class="paragraph">
<p>A UML model for the core GeoPOSE concepts is provided in <a href="#figure-geopose-core">Figure 19</a></p>
</div>
<div id="figure-geopose-core" class="imageblock text-center">
<div class="content">
<img src="images/GeoPOSE_Core.png" alt="GeoPOSE Core">
</div>
<div class="title">Figure 20. GeoPOSE Core</div>
</div>
<div class="paragraph">
<p>The key element in this model is the <code>FrameTransform</code> class. This class expresses a transform between a pair of Reference Frames, Outer and Inner, each defined by a Frame Specification.</p>
</div>
<div class="paragraph">
<p>The Frame Transform is a representation of the transformation taking an Outer Frame coordinate system to an Inner Frame coordinate system. GeoPose v 1.0 supports transformations involving translation and rotation. The intention is to match the usual concept of a pose as a position and orientation.</p>
</div>
<div class="paragraph">
<p>Outer and Inner Frames are subclasses of the the Frame Class. The Frame class provides a standard means of describing transforms for several common coordinate reference systems. Subclasses of the Frame class also include a model for generic reference frames.</p>
</div>
</div>
<div class="sect4">
<h5 id="_time">Time</h5>
<div class="paragraph">
<p>The GeoPOSE time model is rather simple. It does away with calender and restricts time positions to milliseconds of UNIX Time.</p>
</div>
<div id="figure-geopose-time" class="imageblock text-center">
<div class="content">
<img src="images/GeoPOSE_Time.png" alt="GeoPOSE Time">
</div>
<div class="title">Figure 21. GeoPOSE Time</div>
</div>
<div class="paragraph">
<p>The most important classes are GeoPose_Instant (a single point in time) and GeoPose_Duration (a period of time).</p>
</div>
</div>
<div class="sect4">
<h5 id="_sequence">Sequence</h5>
<div class="paragraph">
<p>The sequence logical model defines methods for packaging GeoPose transformations. It addresses the need to integrate multiple GeoPoses which share the same Outer Frame and posess a time-dependent changing Inner Frame.</p>
</div>
<div id="figure-geopose-sequence" class="imageblock text-center">
<div class="content">
<img src="images/GeoPOSE_Sequence.png" alt="GeoPOSE Sequence">
</div>
<div class="title">Figure 22. GeoPOSE Sequence</div>
</div>
<div class="paragraph">
<p>The GeoPOSE Standard provides three models for organizing a collection of Inner Frames.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Stream: the Inner Frame definition (Frame) and an associated time stamp are delivered sequentially.</p>
</li>
<li>
<p>Reqular Series: the Inner Frame definitions are delivered as a sequence, separated by a fixed time interval.</p>
</li>
<li>
<p>Irregular Series: the Inner Frame definitions and associated time stamps are delivered as a collection. There is no explicit spatial or temporal order to the frames.</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_discussions">Discussions</h4>
<div class="paragraph">
<p>Both models express some common concepts:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>There is an "anchor" node which ties the local coordinates to an absolute (external) CRS.</p>
</li>
<li>
<p>Coordinates in one Local coordinate system can be transformed to another through standardized transformations.</p>
</li>
<li>
<p>Local coordinate reference systems are not pre-defined. Sufficient information is defined to describe the transformation between any two arbitrary local coordinate systems.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sect2">
<h3 id="plastic_geometries_section">Plastic Geometries</h3>
<div class="paragraph">
<p>Given a suite of standards which allow you to define time-variant geometric elements, then the next step is to take a collection of those elements and assemble them into a complex object.</p>
</div>
</div>
<div class="sect2">
<h3 id="mass_properties_section">Mass Properties</h3>
<div class="paragraph">
<p>Consider an articulated vehicle in free-flight. As the components change position, they change the center of mass, priciple axis of rotation, and a number of other mass properties. These changes affect the dynamic behavior of the vehicle. Most designers take great care to assure that problems cannot occur. But that doesn&#8217;t mean we should ignore the issue.</p>
</div>
<div class="paragraph">
<p>Comments?</p>
</div>
</div>
<div class="sect2">
<h3 id="kinematics_section">Kinematics</h3>
<div class="paragraph">
<p>Consider an articulated vehicle in free-flight. As the components change position, they change the center of mass, priciple axis of rotation, and a number of other mass properties. These changes affect the dynamic behavior of the vehicle. Most designers take great care to assure that problems cannot occur. But that doesn&#8217;t mean we should ignore the issue.</p>
</div>
<div class="paragraph">
<p>Comments?</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_time_2">Time</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="clocks_and_timers_section">Clocks and Timers</h3>
<div class="sect3">
<h4 id="_misb_timers">MISB Timers</h4>
<div class="paragraph">
<p>Timing is critical for motion imagery. Not only are accurate time stamps essential for the smooth viewing of the images, they are even more critical for the accuracy of data derived from that imagery. Proper geolocation of a moving image, for example, requires nano-precision time stamps.</p>
</div>
<div class="paragraph">
<p>For that reason, the Motion Imagery Standards Board (MISB) developed a timing infrastructure for use with MISB standards. This infrastructure addresses not only the locality of time, but also the conversion of time values from one locality to another.</p>
</div>
<div class="paragraph">
<p>Three timers are illustrated in the example below (T1, T2, and T3). T1 is associated with the Platform. This timer receives regular GPS updates and is considered the most accurate in this system. T2 is associated with Sensor 1. This is a simple oscillator, counting nanoseconds since the sensor was last powered up. T3 is associated with Sensor 2. It also is a simple nanosecond counter.</p>
</div>
<div id="misb_timer_example" class="imageblock text-center">
<div class="content">
<img src="images/Timer_Example.png" alt="Timer Example">
</div>
<div class="title">Figure 23. MISB Timer Example</div>
</div>
<div class="paragraph">
<p>While timers T2 and T3 are sufficient for the operation of their associated sensors, data based on time values from these Timers would not be usable. A transformation from the local time to global time is required.</p>
</div>
<div id="misb_timer_synchronization" class="imageblock text-center">
<div class="content">
<img src="images/MISB_Timer.png" alt="MISB Timer">
</div>
<div class="title">Figure 24. MISB Timer Synchronization</div>
</div>
<div class="paragraph">
<p>figure&#8201;&#8212;&#8201;illustrates the Timer architecture. A Timer is a physical device which provides a time stamp with up to nanosecond precision. The timer is associated with a "Source". The Source specifies how the timer is initallized and how any subsequent corrections are applied. Finally, the TimeTransfer pack defines the metadata available to detect and apply any corrections to the time stamp.</p>
</div>
<div class="paragraph">
<p>The MISB timer concept is specific to the platforms and collection techniques used for Motion Imagery. These can be extended to provide a more general solution.</p>
</div>
</div>
<div class="sect3">
<h4 id="_network_time_protocol">Network Time Protocol</h4>
<div class="paragraph">
<p>Do you really know what time it is?</p>
</div>
<div class="paragraph">
<p>A standard technique for synchronizing clocks is the IETF RFC 5905 Network Time Protocol (NTP).</p>
</div>
<div class="paragraph">
<p>NTP is a client-server protocol. A client requests the time from a Time Server, and the server provides a response with the current time. NTP provides a precision up to 2<sup>-64</sup> seconds. However, precision is not accuracy. It takes time to process the NTP packets. It also takes time for the packets to traverse the network. So the accuracy of NTP can be as low as 0.01 seconds.</p>
</div>
<div class="paragraph">
<p>NTP addresses these sources of error by using a round-trip protocol. The initial request contains one timestamp – the time of the request packet transmission.  The response adds two more timestamps; the time that the request was received and the time that the response packet was transmitted. The final timestamp is the time of the response packet reception. So we have:</p>
</div>
<div class="paragraph">
<p>t<sub>0</sub> – Request packet transmission timestamp</p>
</div>
<div class="paragraph">
<p>t<sub>1</sub> – Request packet reception timestamp</p>
</div>
<div class="paragraph">
<p>t<sub>2</sub> – Response packet transmission timestamp</p>
</div>
<div class="paragraph">
<p>t<sub>3</sub> – Response packet reception timestamp</p>
</div>
<div class="paragraph">
<p>Note that the timestamps must be created as low in the protocol stack as possible to avoid additional CPU processing delays.</p>
</div>
<div class="paragraph">
<p>The difference between the client and server clocks is measured twice. First for the request packet (t<sub>1</sub> – t<sub>0</sub>) and then for the response packet (t<sub>3</sub> – t<sub>2</sub>).  The total clock offset (θ) is the average of these two measures. Mathematically defined by the formula:</p>
</div>
<div class="paragraph">
<p>Θ = ( ( t<sub>1</sub> – t<sub>0</sub> ) + ( t<sub>2</sub> – t<sub>3</sub> ) ) / 2</p>
</div>
<div class="paragraph">
<p>The round-trip delay (δ) is the time spent in transit between the transmission of a request and reception of the response. Mathematically defined by the formula:</p>
</div>
<div class="paragraph">
<p>δ = (t<sub>3</sub> – t<sub>0</sub>) – (t<sub>2</sub> – t<sub>1</sub>)</p>
</div>
<div class="paragraph">
<p>The term t<sub>3</sub> – t<sub>0</sub> represents the total delay while the term t<sub>2</sub> – t<sub>1</sub> represents delay at the server. Since the processing time of an NTP packet should consistent, the second term removes this delay from the measurement. The result is the delay due to network latency, the most dynamic part of the problem.</p>
</div>
<div class="paragraph">
<p>Given these concepts, the NTP protocol can be viewed as follows:</p>
</div>
<div id="network_time_protocol_pseudo_code" class="olist arabic">
<div class="title">Network Time Protocol Pseudo Code</div>
<ol class="arabic">
<li>
<p>Issue an NTP request</p>
</li>
<li>
<p>Receive the response</p>
</li>
<li>
<p>Calculate Θ</p>
</li>
<li>
<p>Calculate δ</p>
</li>
<li>
<p>IF either Θ or δ is a statistical outlier, GOTO 1</p>
</li>
<li>
<p>IF δ is symmetrical (request and response delays
are equal) GOTO 8</p>
</li>
<li>
<p>Adjust the local clock in the direction of Θ (incremental corrections only)</p>
</li>
<li>
<p>Wait a bit</p>
</li>
<li>
<p>GOTO 1</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>This approach assumes a single time server. Additional accuracy can be achieved by using multiple time servers and adjusting to the weighted average of their respective offsets.</p>
</div>
<div class="paragraph">
<p>The NTP has one source of systematic error. If the Time Servers are not accurate, then their clients will not be accurate either. This problem is addressed through an infrastructure of network time servers. At the top (stratum 0) servers are high-precision timekeeping devices such as atomic clocks. Next are the stratum 1 servers. These are servers whose system time is synchronized to within a few microseconds of their <strong><span class="underline">attached</span></strong> stratum 0 devices. Stratum 2 servers are synchronized over a network to stratum 1 servers.  Stratum 3 servers are synchronized over a network to stratum 2 servers.  This pattern can be replicated down to stratum 15. Lower stratums naturally lead to less accuracy.</p>
</div>
<div class="paragraph">
<p>Note: The time server includes its stratum level in the NTP response packet.</p>
</div>
<div id="network_time_protocol" class="imageblock text-center">
<div class="content">
<img src="images/Network_Time_Protocol_servers_and_clients.png" alt="Network Time Protocol servers and clients">
</div>
<div class="title">Figure 25. Network Time Protocol</div>
</div>
</div>
<div class="sect3">
<h4 id="_electronic_distance_measurement">Electronic Distance Measurement</h4>
<div class="paragraph">
<p>Electronic Distance Measurement (EDM) devices operate by sending a laser pulse to a reflective target and measuring the time until the reflection is received back at the instrument. Distance can be calculated using the following formula:</p>
</div>
<div class="paragraph">
<p>ρ = c * (Δt / 2)</p>
</div>
<div class="paragraph">
<p>Where:</p>
</div>
<div class="paragraph">
<p>ρ = the measured distance&lt;</p>
</div>
<div class="paragraph">
<p>c = the speed of light</p>
</div>
<div class="paragraph">
<p>Δt = the interval between emission of the laser pulse and detection of its reflection</p>
</div>
<div class="paragraph">
<p><a href="#electronic_distance_measurement">Figure 25</a> illustrates an EDM measurement. The blue sine wave indicates the emitted light. The Red sine wave indicates the reflection. The value Ρ is the distance between the EDM and the reflector.</p>
</div>
<div id="electronic_distance_measurement" class="imageblock text-center">
<div class="content">
<img src="images/EDM.png" alt="EDM">
</div>
<div class="title">Figure 26. Electronic Distance Measurement</div>
</div>
<div class="paragraph">
<p>Source: GPS for Land Surveyors</p>
</div>
<div class="paragraph">
<p>There is an issue though. With the speed of light at 3.0X10<sup>8</sup> meters per second, a six-nanosecond error in the time measurement would equal a 1-meter error in distance. This level of accuracy is difficult to obtain with an atomic clock. It’s unheard of for a field surveying device. A more precise method is needed.</p>
</div>
<div class="paragraph">
<p>Most EDM devices solve this problem by using the laser as the clock. The laser pulse has a frequency. That frequency corresponds to a wavelength. If we can measure the offset between the transmitted and received signal, we can measure the time delay.</p>
</div>
<div class="paragraph">
<p>The wavelength of a signal can be derived from the frequency using the formula:</p>
</div>
<div class="paragraph">
<p>λ = c / h</p>
</div>
<div class="paragraph">
<p>Where:</p>
</div>
<div class="paragraph">
<p>h = frequency</p>
</div>
<div class="paragraph">
<p>λ = wavelength</p>
</div>
<div class="paragraph">
<p>c = the speed of light</p>
</div>
<div class="paragraph">
<p>Given the wavelength, the distance can be calculated using the formula:</p>
</div>
<div class="paragraph">
<p>Ρ = (N λ + d) / 2</p>
</div>
<div class="paragraph">
<p>Where:</p>
</div>
<div class="paragraph">
<p>N = the number of full wavelengths received at the detector.</p>
</div>
<div class="paragraph">
<p>d = the fractional part of a wavelength received.</p>
</div>
<div class="paragraph">
<p>Note that the higher the frequency of the signal, the greater precision in the distance measurement.</p>
</div>
<div class="paragraph">
<p>The fractional part of the wavelength is the phase shift (figure ---). While high-precision clocks are difficult to build, a tuning circuit capable of measuring the phase shift is simple and inexpensive.</p>
</div>
<div id="edm_phase_shifts" class="imageblock text-center">
<div class="content">
<img src="images/EDM-2.png" alt="EDM 2">
</div>
<div class="title">Figure 27. Phase Shifting in EDM</div>
</div>
<div class="paragraph">
<p>But how do we solve for N? Counting cycles is impractical, particularly since many EDM devices use a continuous wave. The solution is to measure the distance using multiple frequencies. Since lower frequencies have a longer wavelength, we can start with a low-frequency, low-resolution measurement, then incrementally increase the frequency, thereby refining the measurement.</p>
</div>
<div class="paragraph">
<p>Another approach is to encode a pseudo-random sequence onto the signal. The sequence in the reflected signal is then compared to the original. Since we know when the signal was transmitted, any miss-alignment between the reflected sequence and the original indicates the elapsed time (Δt). If the sequence is long enough to span multiple cycles, then N can be found by multiplying Δt by the frequency (h) and rounding down to the nearest whole cycle:</p>
</div>
<div class="paragraph">
<p>N = Δt * h</p>
</div>
<div class="paragraph">
<p>Since the phase shift approach is more precise, most implementations use a code sequence to measure N and phase shift to measure d.</p>
</div>
</div>
<div class="sect3">
<h4 id="_gps">GPS</h4>
<div class="paragraph">
<p>The Global Positioning System (GPS) is the most widely known precise positioning technology we have today. Yet, the GPS satellites obit 20,183 km above the earth surface. How can something so far away provide measurements so precise?</p>
</div>
<div class="sect4">
<h5 id="_gps_time">GPS Time</h5>
<div class="paragraph">
<p>An understanding of precise positioning with GPS first requires an understanding of GPS time.</p>
</div>
<div class="paragraph">
<p>The GPS system consists of a constellation of Earth orbiting satellites. Each satellite is fitted with a highly accurate atomic clock, which is periodically synchronized by a ground control station located at USNO, Colorado. As a result, the GPS satellites share a single synchronized temporal reference system. This temporal reference system is GPS time. USNO ensures that GPS time has an accuracy of ≤40 nanoseconds 95% of the time.</p>
</div>
<div class="paragraph">
<p>The GPS time scale consists of two parts. The first part is a count of the number of weeks since the epoch. Each GPS week is 604,800 seconds long. Since GPS is a monotonic reference system, it does not include leap seconds or years. The second part is the number of seconds in the current week. The start epoch is 0 hours (midnight) Sunday 6-Jan-1980, when GPS time was 0.</p>
</div>
<div class="paragraph">
<p>While the atomic clocks used in GPS satellites are good, they are not perfect. They tend to drift off perfect alignment with GPS time. Furthermore, frequent resetting would degrade the lifespan of the clocks. So, GPS satellites also record the clock bias (τ), the difference between GPS and Space Vehicle (SV) time. This information is provided to the receiver in the NAV message.</p>
</div>
<div class="paragraph">
<p>There are a few rules governing the use of SV time:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Each SV operates on its own SV time,</p>
</li>
<li>
<p>All time-related data in the NAV messages shall be in SV time,</p>
</li>
<li>
<p>All other data in the NAV message shall be relative to GPS time,</p>
</li>
<li>
<p>The acts of transmitting the NAV messages shall be executed on SV time.</p>
</li>
</ol>
</div>
</div>
<div class="sect4">
<h5 id="_gps_signal">GPS Signal</h5>
<div class="paragraph">
<p>GPS signals are driven by the on-board atomic clocks. Four frequency bands are used (see figure --)</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">Band</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">Frequency</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">L1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1575.42 MHz</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">L2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1227.60 MHz</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">L3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1381.05 MHz</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">L5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1176.45 MHz</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The L1 and L2 bands serve as carriers for broadcasting GPS data to GPS receivers. A carrier is not intended to convey information. It serves as a medium upon which other signals can be superimposed. This is the same principle as an FM radio. Your radio is tuned to a carrier frequency. The sound you hear is a separate signal which is superimposed or encoded onto the carrier signal. In the case of GPS, three additional signals are transmitted over the carrier:</p>
</div>
<div class="paragraph">
<p>Navigation Message: The Navigation Message (NAV) provides the receiver with metadata about the satellite. It is broadcast at 50 bps and takes about 30 seconds to transmit. This message includes the satellite ephemeris data, satellite clock corrections, almanac data, ionosphere and troposphere corrections, and satellite health data.</p>
</div>
<div class="paragraph">
<p>C/A Code: The C/A code is a 1023-bit pseudo-random number that repeats every 1 ms. The C/A code is broadcast at the rate of 1.023 Mbps. It has a chip length (distance between binary transitions) of 293 meters. Given a 1023-bit code and a chip length of 293 meters, the C/A sequence repeats every 300 km. (1023 * 293). Its primary purpose is to identify the satellite and to phase-lock the receiver and satellite clocks.</p>
</div>
<div class="paragraph">
<p>P Code: The P code is a pseudo-random number that repeats every 37 weeks. Each GPS satellite is assigned a one-week section of the P code. This section serves as a unique identifier, which helps a GPS receiver distinguish one satellite’s transmission from another. Each satellite broadcasts its’ section of the P code at the rate of 10.23 Mbps. It has a chip length (distance between binary transitions) of 29.3 meters and repeats every seven days. Due to the higher resolution possible at this higher broadcast rate, the P code may be encrypted.</p>
</div>
<div class="paragraph">
<p>In addition to the signals generated by the satellite, GPS receivers generate the same signals based on their own clock. These signals are used to correlate the signals received from the satellite with the local conditions at the receiver.</p>
</div>
</div>
<div class="sect4">
<h5 id="_pseudo_ranging">Pseudo Ranging</h5>
<div class="paragraph">
<p>GPS positioning is based on trilateration. Trilateration calculates a location using three or more control points and the distances to each of those control points (figure --).  In the case of GPS, the control points are satellites located at P<sub>1</sub>, P<sub>2</sub>, and P<sub>3</sub>. The GPS receiver is located at A. If we construct a sphere around each control point (P<sub>i</sub>) of radius (L<sub>i</sub>), then the location of A is at the intersection of the three spheres.</p>
</div>
<div id="gps_pseudo_ranging" class="imageblock text-center">
<div class="content">
<img src="images/three-rings-2.png" alt="three rings 2">
</div>
<div class="title">Figure 28. Pseudo Ranging in GPS</div>
</div>
<div class="paragraph">
<p>Therefore, all we need to know for satellite-based precise positioning is the locations of P<sub>i</sub> and the distances L<sub>i</sub>. Much easier said than done.</p>
</div>
<div class="paragraph">
<p>GPS satellites are tracked to a high degree of precision by the GPS Control Segment. This “ephemeris” data is sent to the satellite every 4 hours. Receivers use a standard “Ephemeris Algorithm” to convert this data into an Earth-centered cartesian (x,y,z) coordinate in the WGS-84 coordinate reference system. However, since the satellites are moving, the calculated position is only valid for a specific time instance. A 1 nano-second (1.0 x 10<sup>-9</sup> seconds) error in time can yield a 30 cm error in range.</p>
</div>
<div class="paragraph">
<p>GPS works on the same basic principles as an EDM device. Unlike an EDA, however, a GPS signal is one-way. The transmitted signal cannot be directly compared with the received signal. So the receiver first calculates the pesudorange observable and iterates to find an accurate solution.</p>
</div>
<div class="paragraph">
<p>The pseudorange is calculated by taking the time required for the signal to reach the receiver and multiplying that value by the speed of light. The basic formula to calculate a pseudorange is:</p>
</div>
<div class="paragraph">
<p>Ρ<sub>i</sub> = c * (t<sub>a</sub> – t<sub>i</sub>)</p>
</div>
<div class="paragraph">
<p>Where:</p>
</div>
<div class="paragraph">
<p>Ρ = the pesudorange for satellite “i”</p>
</div>
<div class="paragraph">
<p>c = the speed of light</p>
</div>
<div class="paragraph">
<p>t<sub>a</sub> = the time at position A when the signal was received.</p>
</div>
<div class="paragraph">
<p>t<sub>i</sub> = the time on satellite “i” when the signal was transmitted.</p>
</div>
<div class="paragraph">
<p>The pseudorange can also be defined in terms of the locations of the satellite and receiver.</p>
</div>
<div class="paragraph">
<p>Ρ<sub>i</sub> = ((x<sub>i</sub> - x)<sup>2</sup> + (y<sub>i</sub> – y)<sup>2</sup> + (z<sub>i</sub> - z)<sup>2</sup>)<sup>1/2</sup> + c( τ ) - c( τ<sub>i</sub> )</p>
</div>
<div class="paragraph">
<p>The terms ((x<sub>i</sub> - x)<sup>2</sup> + (y<sub>i</sub> – y)<sup>2</sup> + (z<sub>i</sub> - z)<sup>2</sup>) are an application of the Pythagorean Theorem (a<sup>2</sup> + b<sup>2</sup> = c<sup>2</sup>). The terms c( τ ) and c( τ<sub>i</sub> ) are the range error introduced by the clock bias at the receiver and on the satellite respectively.</p>
</div>
<div class="paragraph">
<p>Ρ<sub>i</sub> was calculated using equation ---. The satellite location and clock bias was provided through the NAV message. This leaves us with four unknowns. The location of A (x, y, z) and the receiver clock bias (τ). If we are working with four satellites, then that gives up four equations with four unknowns. These four simultaneous equations are usually solved using a least squares method. The result is a reasonably accurate position for A in x, y, z, and t. Repeating this process will refine the results. In particular, improved accuracy of the receiver clock will result in better range accuracy.</p>
</div>
</div>
<div class="sect4">
<h5 id="_carrier_phase_observable">Carrier Phase Observable</h5>
<div class="paragraph">
<p>The pseudo ranging result can be further improved using the Carrier Phase Observable. This approach is similar to the phase shift technique employed by EDM devices. The main difference is that the received signal is compared to the locally generated reference signal rather than the reflection. This gives us the formula:</p>
</div>
<div class="paragraph">
<p>Ρ<sub>i</sub> = N<sub>i</sub> λ + d<sub>i</sub></p>
</div>
<div class="paragraph">
<p>Where:</p>
</div>
<div class="paragraph">
<p>N<sub>i</sub> = the number of full wavelengths received at the detector.</p>
</div>
<div class="paragraph">
<p>λ = wavelength of the carrier</p>
</div>
<div class="paragraph">
<p>d<sub>i</sub> = the fractional part of a wavelength received.</p>
</div>
<div class="paragraph">
<p>We can also represent the carrier phase observation using the Carrier Phase Bias (B<sub>i</sub>) where:</p>
</div>
<div class="paragraph">
<p>B<sub>i</sub> = λ (Φ - Φ<sub>i</sub> - N<sub>i</sub>)</p>
</div>
<div class="paragraph">
<p>Where:</p>
</div>
<div class="paragraph">
<p>Φ = the phase generated by the receiver clock</p>
</div>
<div class="paragraph">
<p>Φ<sub>i</sub> = the phase of the incoming signal</p>
</div>
<div class="paragraph">
<p>Adding the Carrier Phase Bias to the pseudorange gives us:</p>
</div>
<div class="paragraph">
<p>Ρ<sub>i</sub> = ((x<sub>i</sub> - x)<sup>2</sup> + (y<sub>i</sub>
– y)<sup>2</sup> + (z<sub>i</sub> - z)<sup>2</sup>)<sup>1/2</sup> + c( τ ) - c( τ<sub>i</sub> ) + B<sub>i</sub></p>
</div>
<div class="paragraph">
<p>Once again we have four equations solving for four variables: x, y, z, and τ, but with the extra precision added by B<sub>i</sub>.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="temporal_reference_systems_section">Temporal Reference Systems</h3>
<div class="paragraph">
<p>Proposition: Time is in the eye of the beholder.  So all measurements of time must be local.</p>
</div>
<div class="paragraph">
<p>Dynamic Features are not tied to an Earth-centered static existance. Yet the concepts of time used in the geospatial community are almost exclusivly based on Earth-centric astronomical phenomena. They also assume a rather coarse (days, weeks, years) degree of granularity. For dynamic features we need to use local clocks with precision down to the nanosecond. We are less concerned with absolute time than with relative time. State B was achieved 37 nanoseconds after State A.</p>
</div>
<div class="paragraph">
<p>It&#8217;s only when we begin aggregating these dynamic elements that we begin to worry about "absolute" time. Even then, we are more likely to convert from one local clock to another than to convert to an absolute time.</p>
</div>
<div class="paragraph">
<p>So if all time is local, we need a Temporal Reference System concept which captures the parameters needed to transform across TRSs. A temporal equivalent to GeoPOSE.</p>
</div>
<div class="sect3">
<h4 id="_iso_19108">ISO 19108</h4>
<div class="paragraph">
<p>The ISO standard for Temporal Reference Systems is ISO 19108:2006 Geographic Schema - Temporal Schema.</p>
</div>
<div class="paragraph">
<p>In our discussion of <a href="#moving_features_section">Moving Features</a>, we found that time-variant properties of Features were selected using a TM_Coordinate parameter. TM_Coordinate is defined in ISO 19108 and illustrated in Figure ---</p>
</div>
<div id="tm_coordinate_uml_model" class="imageblock">
<div class="content">
<img src="./images/TM_Coordinate.png" alt="TM Coordinate">
</div>
<div class="title">Figure 29. TM_Coordinate UML</div>
</div>
<div class="paragraph">
<p>From this fiqure we see that a TM_Coordinate is a type of TM_TemporalPosition. And that each TM_TemporalPosition is associated with the TM_ReferenceSystem within which it is measured. So to understand Temporal Reference Systems as defined in ISO 19108, we must explore the capabilites and limits of TM_ReferenceSystem.</p>
</div>
<div id="tm_reference_system_uml_model" class="imageblock">
<div class="content">
<img src="./images/TM_ReferenceSystem.png" alt="TM ReferenceSystem">
</div>
<div class="title">Figure 30. TM_ReferenceSystem UML</div>
</div>
<div class="paragraph">
<p>We see from Figure&#8201;&#8212;&#8201;that there are four types of TM_ReferenceSystems. Since our concern is with time, not date, the TM_CoordinateSystem and TM_Clock variants are of most interest.</p>
</div>
<div id="tm_coordinate_system_uml_model" class="imageblock">
<div class="content">
<img src="./images/TM_CoordinateSystem.png" alt="TM CoordinateSystem">
</div>
<div class="title">Figure 31. TM_CoordinateSystem UML</div>
</div>
<div class="paragraph">
<p>TM_CoordinateSystem is "A system for measuring time on a continuous interval scale using a single standard time interval". The standard time interval is provided through the <code>interval</code> attribute. In addition, the <code>origin</code> attribute provides a temporal "datum" from which time is measured. Since time is a one-dimensional quantity, the origin and interval are sufficient to define a basic Temporal Coordinate Reference System.</p>
</div>
<div class="paragraph">
<p>However, TM_CoordinateSystem does have limitations. The transformation operations, for example, only convert to and from DateTime. DateTime is a primitive type defined in ISO 19103. These operations cannot be used to convert from one TM_CoordinateSystem to another. Furthermore. TM_CoordinateSystem does not provide sufficient information to perform these transformations through an outside service.</p>
</div>
<div class="paragraph">
<p>The other alternative is TM_Clock illustrated in Figure&#8201;&#8212;&#8201;</p>
</div>
<div id="tm_clock_uml_model" class="imageblock">
<div class="content">
<img src="./images/TM_Clock.png" alt="TM Clock">
</div>
<div class="title">Figure 32. TM_Clock UML</div>
</div>
<div class="paragraph">
<p>TM_Clock is "A system for measuring temporal position within a day". It has an optional <code>dateBasis</code> association with a calendar (TM_Calendar) class. This allows a TM_Clock to be associated with a TM_Calendar to create a full date-time reference system.</p>
</div>
<div class="paragraph">
<p>TM_Clock posesses the following attributes and operations:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>referenceEvent - The name or description of an event, such as solar noon or sunrise, which fixes the position of the base scale of the clock.</p>
</li>
<li>
<p>referenceTime - The time of day associated with the referenceEvent, expressed as time on this TM_Clock.</p>
</li>
<li>
<p>utcReference - The time of day associated with the referenceEvent expressed as a time in UTC or a related standard time.</p>
</li>
<li>
<p>clkTrans() - This operation accepts a time expressed in UTC and returns a time expressed in this TM_Clock.</p>
</li>
<li>
<p>utcTrans() - This operation accepts a time of day on TM_Clock and returns a time expressed as UTC or a related standard time.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The referenceEvent and referenceTime attributes are particularly interesting. Since these are not restricted in scope, they can be used to define a temporal reference system with an arbitrary origin. For example, an airborn Motion Imagery collection mission can set the referenceEvent value to "takeoff" and the referenceTime to the value of the internal clock when the wheels left the runway.</p>
</div>
<div class="paragraph">
<p>Furthermore, the attributes and operation parameters for TM_Clock are almost exclusively TM_ClockTime classes. A TM_ClockTime is the "time of day measured in a time keeping system other than UTC." Its sole attribute, clkTime, is a sequence of numbers. A suitable representation for a local nanosecond clock.</p>
</div>
<div class="paragraph">
<p>This combination of classes allows us support high precision local-clock TRS as well as full date-time TRS. The only issue is that support for UTC time is required, even for non-terrestrial clocks.</p>
</div>
<div class="paragraph">
<p>At this point it appears that transformations between clocks is not supported by 19108. But there is another avenue we can explore. TM_CoordinateSystem is a subclass of TM_ReferenceSystem. And TM_ReferenceSystem is a subclass of RS_ReferenceSystem. This takes us into ISO 19111: Referencing By Coordinates.</p>
</div>
<div id="coordinate_reference_systems_uml_model" class="imageblock">
<div class="content">
<img src="images/CoordinateReferenceSystems.png" alt="CoordinateReferenceSystems">
</div>
<div class="title">Figure 33. Coordinate Reference Systems</div>
</div>
<div class="paragraph">
<p>In this figure, we see that a TM_ReferenceSystem is an RS_ReferenceSystem as defined in ISO 19111. But it is not an SC_CRS. As such, it does not inherit the additional properties defined in the subclasses of SC_CRS. But we do have a way out. TM_TemporalCRS (defined in 19111 of all places) is a subclass of both SC_SingleCRS (19111) and TM_ReferenceSystem (19108). So if we want to promote Time to a first-class dimension, then TM_TemporalCRS is a good place to start.</p>
</div>
<div class="paragraph">
<p>The question is, what do we need from a temporal coordinate reference system?</p>
</div>
</div>
<div class="sect3">
<h4 id="_misb_timers_2">MISB Timers</h4>
<div class="paragraph">
<p>Timing is critical for motion imagery. Not only are accurate time stamps essential for the smooth viewing of the images, they are even more critical for the accuracy of data derived from that imagery. Proper geolocation of a moving image, for example, requires nano-precision time stamps.</p>
</div>
<div class="paragraph">
<p>For that reason, the Motion Imagery Standards Board (MISB) developed a timing infrastructure for use with MISB standards. This infrastructure addresses not only the locality of time, but also the conversion of time values from one locality to another.</p>
</div>
<div class="paragraph">
<p>Three timers are illustrated in the example below (T1, T2, and T3). T1 is associated with the Platform. This timer receives regular GPS updates and is considered the most accurate in this system. T2 is associated with Sensor 1. This is a simple oscillator, counting nanoseconds since the sensor was last powered up. T3 is associated with Sensor 2. It also is a simple nanosecond counter.</p>
</div>
<div id="misb_timer_reference_system" class="imageblock">
<div class="content">
<img src="./images/Timer_Example.png" alt="Timer Example">
</div>
<div class="title">Figure 34. MISB Timer Refence Systems</div>
</div>
<div class="paragraph">
<p>While timers T2 and T3 are sufficient for the operation of their associated sensors, data based on time values from these Timers would not be usable. A transformation from the local time to global time is required.</p>
</div>
<div id="misb_timer_uml_model" class="imageblock">
<div class="content">
<img src="images/MISB_Timer.png" alt="MISB Timer">
</div>
<div class="title">Figure 35. MISB Timer UML Model</div>
</div>
<div class="paragraph">
<p>figure&#8201;&#8212;&#8201;illustrates the Timer architecture. A Timer is a physical device which provides a time stamp with up to nanosecond precision. The timer is associated with a "Source". The Source specifies how the timer is initallized and how any subsequent corrections are applied. Finally, the TimeTransfer pack defines the metadata available to detect and apply any corrections to the time stamp.</p>
</div>
<div class="paragraph">
<p>The MISB timer concept is specific to the platforms and collection techniques used for Motion Imagery. These can be extended to provide a more general solution.</p>
</div>
</div>
<div class="sect3">
<h4 id="_discussion">Discussion</h4>
<div class="paragraph">
<p>ISO 19108 does not support tranformation between temporal reference systems. However, we can combined ISO 19108 with ISO 19111 to create a rudimentary transformation model for temporal reference systems. This approach will also allow us to minimize the difference between temporal and spatial reference systems.</p>
</div>
<div class="paragraph">
<p>One characteristic of temporal transformations is that the transformation parameters are not static. They are often based on the current state of a physical clock. This suggests that a temporal reference system may include a Moving Feature. A representation of a real-world object with Temporal Properties. The MISB Timer system is an example of this approach. However, the MISB approach is designed for the limited scope of motion imagery collection systems. It does not provide a general solution. Therefore, a more robust model for both Precision Temporal Reference Systems and their transformation is needed.</p>
</div>
<div class="paragraph">
<p>In summary:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>We can define high-precision temporal CRS as subclasses of TM_TemporalCRS.</p>
</li>
<li>
<p>A high-precision temporal CRS is a physical device, a Timer.</p>
</li>
<li>
<p>Precision Time Stamps are created from the local Timer, which is a Temporal CRS</p>
</li>
<li>
<p>Since a Timer is a device, it is also a Feature.</p>
</li>
<li>
<p>Transformation of values from one timer to another requires knowledge of the distance between timers.</p>
</li>
<li>
<p>Since timers can move, they must be Moving Features</p>
</li>
<li>
<p>Transformation parameters may also be time sensitive. So Timers must support termporalProperties.</p>
</li>
<li>
<p>A photon travels roughly 30 centimeters in 1 nanosecond. To achieve and maintain 1 nanosecond accuracy, an accurate measurement of distance, and the associated adjustment, is required.</p>
</li>
<li>
<p>If the timer is traveling very fast, relativistic effects must be accomodated.</p>
</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_reference_systems">Reference Systems</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="planetary_reference_systems_section">Planetary Reference Systems</h3>
<div class="paragraph">
<p>NASA, USGA, and the IAU are developing Reference Systems for non-Earth planetary bodies.</p>
</div>
<div class="paragraph">
<p>ISO 19111 is the international standard for defining Reference Systems</p>
</div>
<div class="paragraph">
<p>Reference EPSG and NSG registry for examples</p>
</div>
<div class="paragraph">
<p>Work to do, further refinement of the existing planetary reference systems and develop ISO 19111 compliant descriptions of those reference systems.</p>
</div>
<div class="paragraph">
<p>Additional work to consider – The Space AOI is likely to require planetary Reference Systems consisting of a point mass with surrounding non-uniform magnetic and gravitational fields. Is this a valid requirement, how do we define such a reference system, and can be extend IAO 19111 to support it.</p>
</div>
</div>
<div class="sect2">
<h3 id="astronomical_reference_systems_section">Astronomical Reference Systems</h3>
<div class="paragraph">
<p>TBD - refer to the International Astronomical Union (IAU)</p>
</div>
</div>
<div class="sect2">
<h3 id="local_reference_systems_section">Local Reference Systems</h3>
<div class="paragraph">
<p>TBD</p>
</div>
</div>
<div class="sect2">
<h3 id="dynamic_reference_systems_section">Dynamic reference Systems</h3>
<div class="paragraph">
<p>TBD</p>
</div>
</div>
<div class="sect2">
<h3 id="space-time_reference_systems_section">Space-Time Reference Systems</h3>
<div class="paragraph">
<p>Minkowski Space Time is a four-dimension Reference System commonly used in Special and General Relativity. It is basically a combination of 3-dimensional Euclidean Space and time into a 4-dimensional manifold, where the interval of spacetime that exists between any two events is not dependent on the inertial frame of reference.</p>
</div>
<div class="paragraph">
<p>Minkowski spacetime is a 4-dimensional coordinate system in which the axes are given by (x, y, z, ct)</p>
</div>
<div class="paragraph">
<p>Where ct is time (t) times the speed of light (c)</p>
</div>
<div class="paragraph">
<p>ds^2 = -c<sup>2dt</sup>2 + dx^2 + dy^2, + dz^2 = the differential arc length in space time where:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>dt = change in time</p>
</li>
<li>
<p>dx = change in x direction</p>
</li>
<li>
<p>dy = change in y direction</p>
</li>
<li>
<p>dz = change in z direction</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Key point - while a Lorentz transformation deals with spatial measurements, Minkowski space includes time as part of that space-time.  Thus ds is an arc length through space-time as opposed to a difference in x as in the Lorentz transform.</p>
</div>
<div class="paragraph">
<p>Question, since c<sup>2dt</sup>2 is a negative term, does that inply that ct is an imaginary number orthagonal to x, y, and z (cti) such that i^2 = -1?</p>
</div>
<div class="paragraph">
<p>Yes for complex Minkowski space time. Here it is expressed as x^2 + y^2 + z^2 + (ict)^2 = const.</p>
</div>
<div class="paragraph">
<p>Complex Minkowski spacetime was replaced with real Minkowski space time where time is a real coordinate rather than an imaginary one.</p>
</div>
<div class="paragraph">
<p>Where v is velocity, and x, y, and z are Cartesian coordinates in 3-dimensional space, and c is the constant representing the universal speed limit, and t is time, the four-dimensional vector v = (ct, x, y, z) = (ct, <strong>r</strong>) is classified according to the sign of (c^2 t^2) − r^2. A vector is <strong>timelike</strong> if (c^2 t^2) &gt; r^2, <strong>spacelike</strong> if (c^2 t^2) &lt; r^2, and <strong>null</strong> or <strong>lightlike</strong> if (c^2 t^2) = r^2. This can be expressed in terms of the sign of η(v, v) as well, which depends on the signature. The classification of any vector will be the same in all frames of reference that are related by a Lorentz transformation (but not by a general Poincaré transformation because the origin may then be displaced) because of the invariance of the interval.</p>
</div>
<div class="sect3">
<h4 id="_lorentz_transformation">Lorentz Transformation</h4>
<div class="paragraph">
<p>A transformation between two different coordinate frames that move at a constant velocity and are relative to each other.</p>
</div>
<div class="paragraph">
<p>Only related to changes in inertial reference frames:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Inertial frames - motion with a constant velocity</p>
</li>
<li>
<p>Non-inertial frames - rotational motion with constant angular velocity, acceleration in curved paths.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In the reference frame "F" which is stationary, the coordinate defined are x, y, z, and t.  In another reference frame F' which moves at a velocity v which is relative to F and the observer defines coordinate in the moving reverence frame as x', y', z', t'. In both the reference frames the coordinate axis are parallel and they remain mutually perpedicular.  The relative motion is along the xx' axes. At t = t' = 0, the origins in both reference frames are the same (x,y,z) = (x',y',z') = (0,0,0).</p>
</div>
<div class="paragraph">
<p>The Lorentz factor g = 1 / (sqrt(1 - (v^2 / c^2)))</p>
</div>
<div class="paragraph">
<p>x' = g(x-vt)
t' = g(t-(vx/c^2))
y' = y
z' = z</p>
</div>
<div class="paragraph">
<p>This is not a complete coordinate transformation since F' has to be rotated and translated so as to be co-linear with F. However, it does add the impact that relative velocity (v) has on the measurements of x and t. In most cases this impact is neglegible (v^2 / c^2 approaches 0).  However, when v is a significant percentage of c it should be applied.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_systems_of_reference_systems">Systems of Reference Systems</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="reference_systems_problem_statement_section">Reference Systems Problem Statement</h3>
<div class="paragraph">
<p>Traditionally we have taken reference systems for granted. Everything was ultimately referenced to the Earth. Not so in Space,</p>
</div>
<div class="paragraph">
<p>Mickelson Moorely shows us that there is no Universal Reference System. All measurements of location are relative. Object A measures the velocity of Object B relative to itself. This measurement is unique to the A-B relationship. There is no absolute measure of velocity that Object B can report to any obserer.</p>
</div>
<div class="paragraph">
<p>Reference System integration - Stages System, GeoPOSE, the need for more complex models</p>
</div>
<div class="paragraph">
<p>The need for a more robust concept of coordinate system transformation.</p>
</div>
</div>
<div class="sect2">
<h3 id="misb_stages_section">MISB Stages</h3>

</div>
<div class="sect2">
<h3 id="geopose_section">GeoPOSE</h3>

</div>
<div class="sect2">
<h3 id="future_work_section">Future and Ongoing Work</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="_special_relativity">Special Relativity</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="relativistic_velocities_section">Dynamic Features at Relativistic Velocities</h3>
<div class="paragraph">
<p>Newtonian physics, the physics of everyday life, served us well for almost 200 years. By the late 1800&#8217;s, however, it became clear that something more was needed.</p>
</div>
<div class="sect3">
<h4 id="_the_birth_of_relativity">The birth of relativity</h4>
<div class="paragraph">
<p>Since light behaves like a wave, there must be a material for the waves to propagate through. Physicists called this material the luminiferous aether. The aether was an undetectable substance which permiates space. It provided a universal reference frame against which absolute motion could be measured.</p>
</div>
<div class="paragraph">
<p>According to this theory, a measurement of the speed of light would vary depending on the motion of the measuring apparatus through the universal reference frame, the aether. The speed of light through the aether would be a fixed value. Measurements of the speed of light would be the sum of the velocity of the measurement appraratus relative to the aether and the speed of light through aether.</p>
</div>
<div class="paragraph">
<p>Consider a measuring apparatus which consists of a light separated a fixed distance from a detector. If the apparatus is oriented in the same direction as the motion of the apparatus through the aether, then the measured speed of light would be higher. If the apparatus was traveling in the opposit direction, then the measured speed of light would be lower.</p>
</div>
<div class="paragraph">
<p>should be higher for an object moving toward a light source and lower for one moving away.</p>
</div>
<div class="paragraph">
<p>In 1887, Michaelson and Morley built such an apparatus. Their experiments showed that the speed of light was the same no matter how their apparatus was oriented. The inescapable conclusion was that there is no luminiferous aether. That there is no universal reference system. There is no abolute motion. All motion must be a measurement of relative motion between two objects.</p>
</div>
</div>
<div class="sect3">
<h4 id="_lorentz_transformation_2">Lorentz Transformation</h4>
<div class="paragraph">
<p>The Lorentz transformations were the result of attempts by Lorentz and others to explain how the speed of light could be independent of the underlying reference frame without discarding the luminiferous aether. While the aether theory is long discarded, Lorentz Transforms are consistent with Special Relativity which makes them still useful today.</p>
</div>
<div class="paragraph">
<p>Consider a reference frame 'A' which is moving in respect to an observer at 'B'. Lorentz asserts that 'A' and 'B' measure reality using two different reference frames. Transformation from reference frame 'A' (Fa) to Reference Frame 'B' (Fb) requires a transformation that accounts for the effect of velocity. Central to this transformation is the The Lorentz factor (g) which is defined as:</p>
</div>
<div class="literalblock">
<div class="content">
<pre>g = 1 / (sqrt(1 - (v^2 / c^2)))</pre>
</div>
</div>
<div class="paragraph">
<p>In each reference frame, an observer can use a local coordinate system (usually Cartesian coordinates in this context) to measure lengths, and a clock to measure time intervals. An event is something that happens at a point in space at an instant of time, or more formally a point in spacetime. The transformations connect the space and time coordinates of an event as measured by an observer in each frame.</p>
</div>
<div class="paragraph">
<p>In the reference frame "F" which is stationary, the coordinate defined are x, y, z, and t.  In another reference frame F' which moves at a velocity v which is relative to F and the observer defines coordinate in the moving reverence frame as x', y', z', t'. In both the reference frames the coordinate axis are parallel and they remain mutually perpedicular.  The relative motion is along the xx' axes. At t = t' = 0, the origins in both reference frames are the same (x,y,z) = (x',y',z') = (0,0,0).</p>
</div>
<div class="paragraph">
<p>x' = g(x-vt)
t' = g(t-(vx/c^2))
y' = y
z' = z</p>
</div>
<div class="paragraph">
<p>Show how a velocity of 1/2 c will generate space and time contraction.</p>
</div>
<div class="paragraph">
<p>This is not a complete coordinate transformation since F' has to be rotated and translated so as to be co-linear with F. However, it does add the impact that relative velocity (v) has on the measurements of x and t. In most cases this impact is neglegible (v^2 / c^2 approaches 0).  However, when v is a significant percentage of c it should be applied.</p>
</div>
</div>
<div class="sect3">
<h4 id="_minkowski_space_time">Minkowski Space Time</h4>
<div class="paragraph">
<p>It is basically a combination of 3-dimensional Euclidean Space and time into a 4-dimensional manifold, where the interval of spacetime that exists between any two events is not dependent on the inertial frame of reference.</p>
</div>
<div class="paragraph">
<p>Minkowski spacetime is a 4-dimensional coordinate system in which the axes are given by (x, y, z, ct)</p>
</div>
<div class="paragraph">
<p>Where ct is time (t) times the speed of light (c)</p>
</div>
<div class="paragraph">
<p>ds^2 = -c^2 dt^2 + dx^2 + dy^2, + dz^2 = the differential arc length in space time where:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>dt = change in time</p>
</li>
<li>
<p>dx = change in x direction</p>
</li>
<li>
<p>dy = change in y direction</p>
</li>
<li>
<p>dz = change in z direction</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Key point - while a Lorentz transformation deals with spatial measurements, Minkowski space includes time as part of that space-time.  Thus ds is an arc length through space-time as opposed to a difference in x as in the Lorentz transform.</p>
</div>
<div class="paragraph">
<p>Question, since c<sup>2dt</sup>2 is a negative term, does that inply that ct is an imaginary number orthagonal to x, y, and z (cti) such that i^2 = -1?</p>
</div>
<div class="paragraph">
<p>Yes for complex Minkowski space time. Here it is expressed as x^2 + y^2 + z^2 + (ict)^2 = const.</p>
</div>
<div class="paragraph">
<p>Complex Minkowski spacetime was replaced with real Minkowski space time where time is a real coordinate rather than an imaginary one.</p>
</div>
<div class="paragraph">
<p>Where v is velocity, and x, y, and z are Cartesian coordinates in 3-dimensional space, and c is the constant representing the universal speed limit, and t is time, the four-dimensional vector v = (ct, x, y, z) = (ct, <strong>r</strong>) is classified according to the sign of (c^2 t^2) − r^2. A vector is <strong>timelike</strong> if (c^2 t^2) &gt; r^2, <strong>spacelike</strong> if (c^2 t^2) &lt; r^2, and <strong>null</strong> or <strong>lightlike</strong> if (c^2 t^2) = r^2. This can be expressed in terms of the sign of η(v, v) as well, which depends on the signature. The classification of any vector will be the same in all frames of reference that are related by a Lorentz transformation (but not by a general Poincaré transformation because the origin may then be displaced) because of the invariance of the interval.</p>
</div>
</div>
<div class="sect3">
<h4 id="_musings">Musings</h4>
<div class="paragraph">
<p>A Minkowski coordinate reference system is M4D.</p>
</div>
<div class="paragraph">
<p>Minkowski spacetime has no natural CRS. All M4D CRS are local.</p>
</div>
<div class="paragraph">
<p>M4D is a spatial CRS. the axis are x, y, z, and ct.</p>
</div>
<div class="paragraph">
<p>Note the units of ct &#8594; M/S * S = M &#8594; all axis of a M4D CRS have the same units of measure.</p>
</div>
<div class="paragraph">
<p>Consider an Observer O and an Observed phenomenon O'.</p>
</div>
<div class="paragraph">
<p>Discuss Worlds and world lines</p>
</div>
<div class="paragraph">
<p>If O' is stationary in respect to O, then Newtonian physics applies.</p>
</div>
<div class="paragraph">
<p>If O' is moving in respect to O, then it has a world line as shown in figure ---</p>
</div>
<div class="paragraph">
<p>Notice that the M4D CRS of O' is inclined in respect to the CRS of O. It has undergone a rotation. The effect of this rotation is a contraction in both the measured X and ct coordinates. The ammount of contraction depends on the rotation of M4D O' in respect to M4D O.</p>
</div>
<div class="paragraph">
<p>So M4D O' and M4D O can be evaluated in terms of our standard concepts of translation and rotation.</p>
</div>
<div class="paragraph">
<p>The actual mathematics involved can be packaged in a reusable library, similar to the way terrestrial CRS conversions are handled by GeoTRANS. It is sufficient for geospatial users to understand the required parameters and the basic principles of the transforms.</p>
</div>
<div class="paragraph">
<p>Also - this requires that the general practice of measuring across coordinate reference systems be matured. CRS and CRS transformation will play a much larger role in spatial-temporal data processing than it has in the past.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="recommendations_section">Discussions and Recommendations</h3>
<div class="paragraph">
<p>TBD</p>
</div>
<div class="paragraph">
<p>Quaternions vs. Euler rotations</p>
</div>
<div class="paragraph">
<p>Temporal representation - Unix time vs the Timer model.</p>
</div>
<div class="paragraph">
<p>Standarize on a right-handed Cartisian coorinate system for all stages/Poses?</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_revision_history">Annex A: Revision History</h2>
<div class="sectionbody">
<table class="tableblock frame-all grid-all" style="width: 90%;">
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Date</th>
<th class="tableblock halign-left valign-top">Release</th>
<th class="tableblock halign-left valign-top">Editor</th>
<th class="tableblock halign-left valign-top">Primary clauses modified</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">2016-04-28</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">G. Editor</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">all</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">initial version</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="glossary_section">Glossary</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The following terms and definitions are used in this Discussion Paper.</p>
</div>
<div class="sect2">
<h3 id="base_representation_definition"><strong>base representation</strong></h3>
<div class="paragraph">
<p>&lt;moving features〉representation, using a local origin and local ordinate vectors, of a geometric object at a given reference time [ISO 19141:2008, definition 4.1.1]</p>
</div>
<div class="paragraph">
<p>NOTE 1 A rigid geometric object may undergo translation or rotation, but remains congruent with its base representation.</p>
</div>
<div class="paragraph">
<p>NOTE 2 The local origin and ordinate vectors establish an engineering coordinate reference system (ISO 19111), also called a local frame or a local Euclidean coordinate system.</p>
</div>
</div>
<div class="sect2">
<h3 id="design_coordinate_reference_system_definition"><strong>design coordinate reference system</strong></h3>
<div class="paragraph">
<p>engineering coordinate reference system in which the base representation of a moving object is specified. [ISO 19141:2008, definition 4.1.3]</p>
</div>
</div>
<div class="sect2">
<h3 id="direct_position_definition"><strong>direct position</strong></h3>
<div class="paragraph">
<p>DirectPosition object data types hold the coordinates for a position within some coordinate reference system.</p>
</div>
</div>
<div class="sect2">
<h3 id="external_coordinate_reference_system_definition"><strong>external coordinate reference system</strong></h3>
<div class="paragraph">
<p>the coordinate reference system in which the geometry of the curve for a trajectory is defined. Usually an earth-fixed geographic CRS. [ISO 19141:2008, derived]</p>
</div>
</div>
<div class="sect2">
<h3 id="feature_definition"><strong>feature</strong></h3>
<div class="paragraph">
<p>abstraction of real world phenomena [ISO 19101:2002, definition 4.11]</p>
</div>
<div class="paragraph">
<p>NOTE A feature may occur as a type or an instance. Feature type or feature instance shall be used when only one is meant.</p>
</div>
</div>
<div class="sect2">
<h3 id="foliation_definition"><strong>foliation</strong></h3>
<div class="paragraph">
<p>one parameter set of geometries such that each point in the prism of the set is in one and only one trajectory and in one and only one leaf [ISO 19141:2008, definition 4.1.8]</p>
</div>
</div>
<div class="sect2">
<h3 id="geometric_object_definition"><strong>geometric object</strong></h3>
<div class="paragraph">
<p>spatial object representing a geometric set [ISO 19107:2003, definition 4.47]</p>
</div>
</div>
<div class="sect2">
<h3 id="geometric_primitive_definition"><strong>geometric primitive</strong></h3>
<div class="paragraph">
<p>geometric object representing a single, connected, homogeneous element of space [ISO 19107:2003, definition 4.48]</p>
</div>
<div class="paragraph">
<p>NOTE Geometric primitives are non-decomposed objects that present information about geometric configuration. They include points, curves, surfaces, and solids.</p>
</div>
</div>
<div class="sect2">
<h3 id="global_coordinate_reference_system_definition"><strong>global coordinate system</strong></h3>
<div class="paragraph">
<p>the CRS of the trajectory of the reference point.</p>
</div>
<div class="paragraph">
<p>NOTE A global coordinate system is usually in terms of the moving frame of the curve (oriented on the local tangent) or in terms of the external CRS in which the geometry of the curve is defined. [ISO 19141:2008, derived]</p>
</div>
</div>
<div class="sect2">
<h3 id="gm_point_definition"><strong>GM_Point</strong></h3>
<div class="paragraph">
<p>GM_Point is the basic data type for a geometric object consisting of one and only one point. That point is represented as a DirectPosition.</p>
</div>
</div>
<div class="sect2">
<h3 id="inertial_frame_definition"><strong>Inertial Frame</strong></h3>
<div class="paragraph">
<p>relative motion with constant velocity</p>
</div>
</div>
<div class="sect2">
<h3 id="instant_definition"><strong>instant</strong></h3>
<div class="paragraph">
<p>0-dimensional geometric primitive representing position in time [ISO 19108:2002, definition 4.1.17]</p>
</div>
</div>
<div class="sect2">
<h3 id="leaf_definition"><strong>leaf</strong></h3>
<div class="paragraph">
<p>&lt;one parameter set of geometries&gt; geometry at a particular value of the parameter [ISO 19141:2008, definition 4.1.12]</p>
</div>
</div>
<div class="sect2">
<h3 id="local_coordinate_reference_system_definition"><strong>local coordinate system</strong></h3>
<div class="paragraph">
<p>a coordinate reference system which is internal to the Feature. This is usually a cartisian coordinate system with the origin at a prominant point in the Feature such as the center of mass.</p>
</div>
</div>
<div class="sect2">
<h3 id="non-inertial_frame_definition"><strong>Non-Inertial Frame</strong></h3>
<div class="paragraph">
<p>accelerating, moving in curved paths, rotational motion with constant angular velocity, etc.</p>
</div>
</div>
<div class="sect2">
<h3 id="one_parameter_geometries_set_definition"><strong>one parameter set of geometries</strong></h3>
<div class="paragraph">
<p>function f from an interval t ∈ [a, b] such that f(t) is a geometry and for each point P ∈ f(a) there is a one parameter set of points (called the trajectory of P) P(t) : [a, b] →P(t) such that P(t) ∈ f(t) [ISO 19141:2008, definition 4.1.15]</p>
</div>
<div class="paragraph">
<p>EXAMPLE A curve C with constructive parameter t is a one parameter set of points c(t).</p>
</div>
</div>
<div class="sect2">
<h3 id="prism_definition"><strong>prism</strong></h3>
<div class="paragraph">
<p>&lt;one parameter set of geometries&gt; set of points in the union of the geometries (or the union of the trajectories) of a one parameter set of geometries [ISO 19141:2008, definition 4.1.18]</p>
</div>
<div class="paragraph">
<p>NOTE This is a generalization of the concept of a geometric prism that is the convex hull of two congruent polygons in 3D-space. Such polyhedrons can be viewed as a foliation of congruent polygons.</p>
</div>
</div>
<div class="sect2">
<h3 id="temporal_coordinate_system_definition"><strong>temporal coordinate system</strong></h3>
<div class="paragraph">
<p>temporal reference system based on an interval scale on which distance is measured as a multiple of a single unit of time [ISO 19108:2002, definition 4.1.31]</p>
</div>
</div>
<div class="sect2">
<h3 id="temporal_position_definition"><strong>temporal position</strong></h3>
<div class="paragraph">
<p>location relative to a temporal reference system [ISO 19108:2002, definition 4.1.34]</p>
</div>
</div>
<div class="sect2">
<h3 id="temporal_reference_system_definition"><strong>temporal reference system</strong></h3>
<div class="paragraph">
<p>reference system against which time is measured [ISO 19108:2002, definition 4.1.35]</p>
</div>
</div>
<div class="sect2">
<h3 id="trajectory_definition"><strong>trajectory</strong></h3>
<div class="paragraph">
<p>path of a moving point described by a one parameter set of points [ISO 19141:2008, definition 4.1.22]</p>
</div>
</div>
<div class="sect2">
<h3 id="vector_definition"><strong>vector</strong></h3>
<div class="paragraph">
<p>quantity having direction as well as magnitude [ISO 19123:2005, definition 4.1.43]</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="bibliography_section">Bibliography</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Hughes, P. :Spacecraft Attitude Dynamics, Dover Publications Inc. 2024</p>
</div>
<div class="paragraph">
<p>ISO/TC 211: ISO 19107:2019 Geographic information - Spatial schema</p>
</div>
<div class="paragraph">
<p>ISO/TC 211: ISO 19107:2003 Geographic information - Spatial schema</p>
</div>
<div class="paragraph">
<p>ISO/TC 211: ISO 19109:2005 Geographic information - Rules for application schema</p>
</div>
<div class="paragraph">
<p>ISO/TC 211: ISO 19109:2005 Geographic information - Rules for application schema</p>
</div>
<div class="paragraph">
<p>ISO/TC 211: ISO 19141:2008 Geographic information - Schema for moving features</p>
</div>
<div class="paragraph">
<p>OGC: OGC 20-010, OGC City Geography Markup Language (CityGML) Part 1: Conceptual Model Standard (2021)</p>
</div>
<div class="paragraph">
<p>OGC: OGC 19-011r4, OGC IndoorGML 1.1 (2020)</p>
</div>
<div class="paragraph">
<p>OGC: OGC 19-045r3, OGC Moving Features Encoding Extension - JSON (2020)</p>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2022-11-16 14:33:35 UTC
</div>
</div>
</body>
</html>